{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4718e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!hf auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "962827c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 3358 training samples.\n",
      "Using device: cuda\n",
      " Loading model: HuggingFaceTB/SmolLM3-3B\n",
      "Model loaded on device: cuda\n",
      "Loading dataset...\n",
      "Loaded 720 samples for inference.\n",
      "Saved test split to test_split.csv for evaluation consistency.\n",
      "Starting zero-shot / few-shot inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|#####     | 1/2 [00:02<00:02,  2.46s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [00:03<00:00,  1.35s/it]\n",
      "Loading checkpoint shards: 100%|##########| 2/2 [00:03<00:00,  1.51s/it]\n",
      "\n",
      "Map:   0%|          | 0/3358 [00:00<?, ? examples/s]\n",
      "Map:  60%|#####9    | 2000/3358 [00:00<00:00, 10626.86 examples/s]\n",
      "Map: 100%|##########| 3358/3358 [00:00<00:00, 10920.41 examples/s]\n",
      "Map: 100%|##########| 3358/3358 [00:00<00:00, 10866.78 examples/s]\n",
      "\n",
      "Map:   0%|          | 0/720 [00:00<?, ? examples/s]\n",
      "Map: 100%|##########| 720/720 [00:00<00:00, 10282.36 examples/s]\n",
      "\n",
      "Map:   0%|          | 0/720 [00:00<?, ? examples/s]\n",
      "Map: 100%|##########| 720/720 [00:00<00:00, 11998.72 examples/s]\n",
      "\n",
      "  0%|          | 0/720 [00:00<?, ?it/s]\n",
      "  0%|          | 0/720 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\run_experiments.py\", line 60, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\run_experiments.py\", line 45, in main\n",
      "    inference.run_inference()\n",
      "  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\zero_shot_inference.py\", line 147, in run_inference\n",
      "    logger(prompt)\n",
      "  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\utils.py\", line 17, in __call__\n",
      "    print(message)\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 0-3: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "!python run_experiments.py --model \"Qwen/Qwen2.5-1.5B-Instruct\" --csv_path \"ground_truth.csv\" --prompt_style 1 --shots 0 --save_path \"./zs_preds\" --call_limit 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba41912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\zero_shot_evaluation.py\", line 3, in <module>\n",
      "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 53, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\numexpr\\__init__.py\", line 26, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n",
      "AttributeError: _ARRAY_API not found\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\zero_shot_evaluation.py\", line 3, in <module>\n",
      "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 80, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 67, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\site-packages\\bottleneck\\__init__.py\", line 2, in <module>\n",
      "    from .reduce import (\n",
      "AttributeError: _ARRAY_API not found\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\zero_shot_evaluation.py\", line 133, in <module>\n",
      "    e.classification()\n",
      "  File \"C:\\Users\\mkahmed\\Desktop\\miniproject\\zero_shot_evaluation.py\", line 103, in classification\n",
      "    print(f\"\\U0001f4dd Cleaned predictions saved to: {debug_path}\")\n",
      "  File \"C:\\Users\\mkahmed\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f4dd' in position 0: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "!python zero_shot_evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f3f1314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9137301a361340309c31d6d2c47909ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following Arabic text. \n",
      "Decide if it was written by a human or an AI model.\n",
      "Answer ONLY one word in Arabic, INSIDE the tags <answer>...</answer>.\n",
      "Use 'بشري' for human, 'آلة' for machine.\n",
      "\n",
      "النص: هذا النص يتحدث عن الطقس في الرياض اليوم حيث كانت الأجواء مشمسة ودافئة.\n",
      "\n",
      "الإجابة:  <answer>بشري</answer>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "حل آخر: \n",
      "النص: منشور على موقع التواصل الاجتماعي يحتوي على تع\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"HuggingFaceTB/SmolLM3-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "text = \"\"\"Classify the following Arabic text. \n",
    "Decide if it was written by a human or an AI model.\n",
    "Answer ONLY one word in Arabic, INSIDE the tags <answer>...</answer>.\n",
    "Use 'بشري' for human, 'آلة' for machine.\n",
    "\n",
    "النص: هذا النص يتحدث عن الطقس في الرياض اليوم حيث كانت الأجواء مشمسة ودافئة.\n",
    "\n",
    "الإجابة: \"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=30)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea215915",
   "metadata": {},
   "outputs": [],
   "source": [
    "python run_experiments_fewshot.py --model \"Qwen/Qwen2.5-1.5B-Instruct\" --csv_path \"ground_truth.csv\" --prompt_style 1 --shots 3 --save_path \"./fs_preds\" --call_limit 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b55ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e28b819b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  9 19:29:04 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.83                 Driver Version: 576.83         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3080 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8             25W /  145W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e9dc0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to set driver model for GPU 00000000:01:00.0: Insufficient Permissions\n",
      "Terminating early due to previous errors.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -dm 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9efe24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
