import warnings
import os
import pickle
import pandas as pd
from datasets import Dataset
import numpy as np

warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from huggingface_hub import login
from datasets import load_dataset

class FT_Dataset:
    def __init__(self, EOS_TOKEN, split="train", shots=0, logger = None, test_mode=False, shuffle=False):
        login(token="hf_token")

        assert shots in [0, 1, 3, 5, 10], "Shots should be one of 0, 1, 3, 5, 10"
        self.shots = shots

        self.EOS_TOKEN = "" if test_mode else EOS_TOKEN
        self.split = split
        self.logger = logger
        self.test_mode = test_mode

        self.shuffle = shuffle

        print("WILL SHUFFLE: " + str(self.shuffle) + " =====================================")

        self.dataset_names = {
            "sentiment_train":"ajgt_twitter_ar",
            "sentiment_test":"ajgt_twitter_ar",

            "pos_tagging_train":"universal_dependencies",
            "pos_tagging_test":"universal_dependencies",

            "summarization_train":"./data/sum_train.csv",
            "summarization_test":"./data/sum_test.csv",

            "translation_train":"./data/translation_train.csv",
            "translation_test":"./data/translation_test.csv",

            "paraphrasing_train": "aishaalansari/paraphrase" ,
            "paraphrasing_test": "aishaalansari/Paraphrasing",

            "transliteration_train": "./data/transliteration_train.csv",
            "transliteration_test": "./data/transliteration_test.csv",

            "sqs_train": "./data/sqs_train.csv",
            "sqs_test": "./data/sqs_test.csv",

            "stance_train": "./data/stance_train.csv",
            "stance_test": "./data/stance_test.csv",

            "claim_train": "./data/claim_train.csv",
            "claim_test": "./data/claim_test.csv",

            "wsd_train": "./data/wsd_train.csv",
            "wsd_test": "./data/wsd_test.csv",

            # "mcq_train":"aishaalansari/CIDAR100",
            # "mcq_test":"aishaalansari/CIDAR100",

            "GQA_train": "asas-ai/tydiqa-goldp-ar",
            "GQA_test": "asas-ai/tydiqa-goldp-ar",

            # "diacratization_train":"arbml/tashkeelav2",
            # "diacratization_test":"arbml/tashkeelav2",

            "sarcasm_train": "./data/sarc_dab_train.csv",
            "sarcasm_test": "./data/sarc_dab_test.csv",

            "dialect_train": "./data/sarc_dab_train.csv",
            "dialect_test":  "./data/sarc_dab_test.csv",

            "hate_train": "./data/off_hs_train.csv",
            "hate_test": "./data/off_hs_test.csv",

            "offensive_train": "./data/off_hs_train.csv",
            "offensive_test": "./data/off_hs_test.csv",
        }

        self.dataset_splits = {
            "sentiment_train":"train[:1440]",
            "sentiment_test":"train[1440:]",

            "pos_tagging_train":"train",
            "pos_tagging_test":"test",

            "summarization_train":"train",
            "summarization_test":"train",

            "translation_train":"train",
            "translation_test":"test",

            "paraphrasing_train": "train",
            "paraphrasing_test": "train",

            "transliteration_train": "train",
            "transliteration_test": "test",

            "sqs_train":"train",
            "sqs_test":"test",

            "claim_train":"train",
            "claim_test":"test",

            "stance_train":"train",
            "stance_test":"test",

            # "mcq_train":"train",
            # "mcq_test":"test",

            "GQA_train": "train",
            "GQA_test": "validation",

            # "diacratization_train":"train",
            # "diacratization_test":"test",
        }

        self.subset_names = {
            "sentiment_train": None,
            "sentiment_test": None,

            # "diacratization_train": None,
            # "diacratization_test": None,

            # "mcq_train": None,
            # "mcq_test": None,

            "pos_tagging_train": "ar_padt",
            "pos_tagging_test": "ar_padt",

            "paraphrasing_train": None,
            "paraphrasing_test": None,

            "GQA_train": None,
            "GQA_test": None,
        }

        self.prompt_func_map = {
            "sentiment_train": self.format_prompt_sentiment,
            "sentiment_test": self.format_prompt_sentiment,

            # "diacratization_train": self.format_prompt_diacratization,
            # "diacratization_test": self.format_prompt_diacratization,

            # "mcq_train": self.format_prompt_mcq,
            # "mcq_test": self.format_prompt_mcq,

            "pos_tagging_train": self.format_prompt_postagging,
            "pos_tagging_test": self.format_prompt_postagging,

            "summarization_train": self.format_prompt_summarization,
            "summarization_test": self.format_prompt_summarization,

            "translation_train": self.format_prompt_translation,
            "translation_test": self.format_prompt_translation,

            "paraphrasing_train": self.format_prompt_paraphrasing,
            "paraphrasing_test": self.format_prompt_paraphrasing,

            "transliteration_train": self.format_prompt_transliteration,
            "transliteration_test": self.format_prompt_transliteration,

            "GQA_train": self.format_prompt_GQA,
            "GQA_test": self.format_prompt_GQA,

            "sqs_train": self.format_prompt_sqs,
            "sqs_test": self.format_prompt_sqs,

            "claim_train": self.format_prompt_claim,
            "claim_test": self.format_prompt_claim,

            "stance_train": self.format_prompt_stance,
            "stance_test": self.format_prompt_stance,

            "wsd_train": self.format_prompt_wsd,
            "wsd_test": self.format_prompt_wsd,

            "sarcasm_train": self.format_prompt_sarcasm,
            "sarcasm_test": self.format_prompt_sarcasm,

            "dialect_train": self.format_prompt_dialect,
            "dialect_test": self.format_prompt_dialect,

            "hate_train": self.format_prompt_hate,
            "hate_test": self.format_prompt_hate,

            "offensive_train": self.format_prompt_offensive,
            "offensive_test": self.format_prompt_offensive,
        }

        # =============================================
        self.task_instructions = {
            "summarization": "Can you summarize the following text in one sentence? Give the answer in arabic.",
            "paraphrasing": "Paraphrase the following text while keeping the meaning intact. Give the answer in arabic.",
            "offensive": "Does this text contain offensive language? Type '1' for Offensive and '0' for Not Offensive.",
            "GQA":"What is the answer for the following question?",
            
            "grammar": "Correct the grammatical errors in this sentence",
            # "grammar": "Does this sentence have any grammatical errors? If yes, provide the correction. Otherwise, re-write the sentence",
            # "grammar": "You are a professional proofreader. Read the following sentence and correct any grammatical mistakes",
        }

        self.task_instructions_ar = {
            "sentiment": "ØµÙ†Ù Ù…Ø´Ø§Ø¹Ø± Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø© ÙƒÙ€ 0 Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø³Ù„Ø¨ÙŠØ© Ùˆ 1 Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©. Ù‚Ù… Ø¨Ø§Ù„Ø§Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ",
            "translation": "ØªØ±Ø¬Ù… Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
            "transliteration": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ø¨Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© ÙˆÙÙ‚Ù‹Ø§ Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ²ÙŠ. Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù‚Ù… Ø¨Ø§Ù„Ø§Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ",
            "dialect": "Ù‡Ù„ ÙƒÙØªØ¨ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø£Ù… Ø¨Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø§Ù…ÙŠØ©ØŸ Ø§ÙƒØªØ¨ '0' Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø§Ù„ÙØµØ­Ù‰ Ùˆ'1' Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø§Ù„Ø¹Ø§Ù…ÙŠØ©.",
            "stance": "Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙˆÙ‚Ù Ø¨ÙŠÙ† Ø§Ù„Ø¬Ù…Ù„ØªÙŠÙ† Ø§Ù„Ù…Ø¹Ø·ÙŠØªÙŠÙ†. Ø§Ø®ØªØ± Ø£Ø­Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©: (0) Ø§Ø®ØªÙ„Ø§ÙØŒ (1) Ø§ØªÙØ§Ù‚ØŒ (2) ØºÙŠØ± ÙˆØ§Ø¶Ø­/ØºÙŠØ± Ù…Ø±ØªØ¨Ø·.",
            "claim": "Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡ Ø²Ø§Ø¦ÙØŸ Ø§ÙƒØªØ¨ '1' Ø¥Ø°Ø§ ÙƒØ§Ù† Ø²Ø§Ø¦ÙÙ‹Ø§ Ùˆ'0' Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙƒØ°Ù„Ùƒ.",
            "wsd": "Ù‡Ù„ ÙŠØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù…Ø¹Ø·Ù‰ Ù…Ø¹ Ù…Ø¹Ù†Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø©ØŸ Ø§ÙƒØªØ¨ '1' Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ·Ø§Ø¨Ù‚Ù‹Ø§ Ùˆ'0' Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙƒØ°Ù„Ùƒ.",
            "sqs": "Ù‡Ù„ ØªÙ…Øª Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø¥Ø­Ø¯Ù‰ Ø§Ù„Ø¬Ù…Ù„ØªÙŠÙ† Ù„ØªÙƒÙˆÙ† Ù…ÙƒØ§ÙØ¦Ø© Ù„Ù„Ø£Ø®Ø±Ù‰ØŸ Ø£Ø¬Ø¨ Ø¨Ù€ '1' Ø¥Ø°Ø§ ÙƒØ§Ù†ØªØ§ Ù…Ø¹Ø§Ø¯ØªÙŠ Ø§Ù„ØµÙŠØ§ØºØ© Ùˆ'0' Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙˆÙ†Ø§ ÙƒØ°Ù„Ùƒ.",
            "hate": "ØµÙ†Ù Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙƒÙ€ 0 Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø®Ø·Ø§Ø¨ ÙƒØ±Ø§Ù‡ÙŠØ© Ùˆ 1 Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø®Ø·Ø§Ø¨ ÙƒØ±Ø§Ù‡ÙŠØ©",
            "pos_tagging": "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„ØµØ±ÙÙŠ Ø§Ù„ØµØ­ÙŠØ­ Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø©ØŸ Ø­Ø¯Ø¯ Ø§Ù„ÙˆØ³Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„ÙƒÙ„ ÙƒÙ„Ù…Ø© Ù…Ù† Ø¨ÙŠÙ† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©: ['NOUN', 'PUNCT', 'ADP', 'NUM', 'SYM', 'SCONJ', 'ADJ', 'PART', 'DET', 'CCONJ', 'PROPN', 'PRON', 'X', 'ADV', 'INTJ', 'VERB', 'AUX'].",
            "sarcasm": "ØµÙ†Ù Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙƒÙ€ 0 Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø³Ø§Ø®Ø±Ø§Ù‹ Ùˆ 1 Ø¥Ø°Ø§ ÙƒØ§Ù† Ø³Ø§Ø®Ø±Ø§Ù‹",

            "grammar": "ØµØ­Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù†Ø­ÙˆÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø©",
            # "grammar": "Ù‡Ù„ ØªØ­ØªÙˆÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø£Ø®Ø·Ø§Ø¡ Ù†Ø­ÙˆÙŠØ©ØŸ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù†Ø¹Ù…ØŒ Ù‚Ù… Ø¨ØªØµØ­ÙŠØ­ Ø§Ù„Ø¬Ù…Ù„Ø©. Ø§Ù† ÙƒØ§Ù†Øª Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ø®Ø·Ø§Ø¡ Ù‚Ù… Ø¨Ø§Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¬Ù…Ù„Ø©.",
            # "grammar": "Ø£Ù†Øª Ù…Ø¯Ù‚Ù‚ Ù„ØºÙˆÙŠ Ù…Ø­ØªØ±Ù. Ø§Ù‚Ø±Ø£ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØµØ­Ø­ Ø£ÙŠ Ø£Ø®Ø·Ø§Ø¡ Ù†Ø­ÙˆÙŠØ©"
        }
        # =============================================


        self.size = -1

    def get_size(self):
        assert self.size > 0, "Call get_dataset() first !!!"
        return self.size
    
    def format_prompt_offensive(self, data):
        inputs = data["tweet"]
        outputs = data["offensive"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(inputs), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + inputs[i] + "\n\n" + self.a_head + "<answer>" + str(outputs[i]) + "</answer>\n\n"

        examples = ""
        shot_inputs = [
            "@USER @USER Ø¯ÙŠÙ…ÙˆÙƒØ±Ø§ØªÙŠØ© Ø¯Ù‰ ÙˆÙ„Ø§ Ù…ÙˆØ´ Ø¯ÙŠÙ…ÙˆÙƒØ±Ø§ØªÙŠØ© ÙŠØ§ Ù…ØªØ¹Ù„Ù…ÙŠÙ† ÙŠØ§ Ø¨ØªÙˆØ¹ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ ðŸ˜‚ðŸ˜‚ðŸ˜‚",
            "@USER Ø¨Ø³ Ø¹ÙŠØ¨ Ø§Ù„Ù„ÙŠ ÙŠØµÙŠØ± Ù…Ù† Ø§Ù„Ø¬Ø­Ø¯ ÙˆØ§Ù„Ù†ÙƒØ±Ø§Ù† ÙŠØ§ Ù†Ø´Ø¬Ø¹Ù‡ ÙŠØ§ Ù†Ø³ÙƒØª Ø§Ù…Ø§ Ø§Ù„Ù†ÙƒØ±Ø§Ù† Ø°Ø§ Ø¹ÙŠØ¨",
            "ÙŠØ§ Ø¬Ø§Ù…Ø¹ÙŠØ© ÙŠØ§ ÙØ§Ù‡Ù…Ø© Ùˆ ÙŠØ§ Ø¹Ø§Ù‚Ù„Ø© Ù…Ø§ Ø¨ØªÙ…ÙˆØªÙŠÙ† Ø§Ø°Ø§ Ø´Ù„ÙŠØªÙŠ ÙˆØµØ§Ø®ØªØ¬ Ùˆ Ù‚Ø·ÙŠØªÙŠÙ‡Ù… ÙØ§Ù„Ø²Ø¨Ø§Ù„Ø©ðŸ™‚",
            "RT @USER: Ù†Ø§Ù…ÙˆØ§ Ù†Ø§Ù…Øª Ø¹Ù„ÙŠÙƒÙˆØ§ Ø­ÙŠØ·Ù‡ ÙŠØ§ Ù…ÙƒØªØ¦Ø¨ÙŠÙ† ÙŠØ§ Ø£Ø¹Ø¯Ø§Ø¡ Ø§Ù„ÙØ±Ø­Ù‡ Ù†Ø§Ù…ÙˆØ§",
            "@USER ÙŠØ§ Ù†ÙƒØ¯ÙŠ ÙŠØ§ Ø·Ø§Ù‚ÙŠÙ‡ Ø®Ù„Ù†Ø§ Ù…Ø¨Ø³ÙˆØ·ÙŠÙ†",
        ]
        shot_outputs = ["0", "0", "1", "1", "1"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shot_inputs[i] + "\n\n" + self.a_head + "<answer>" + shot_outputs[i] + "</answer>\n\n"
            
        
        for text, label in zip(inputs, outputs):
            text = self.prompt_template.format(examples, text, label if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}
    
    def format_prompt_hate(self, data):
        inputs = data["tweet"]
        outputs = data["hate"]
        texts = []
        
        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(inputs), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + inputs[i] + "\n\n" + self.a_head + "<answer>" + str(outputs[i]) + "</answer>\n\n"

        examples = ""
        shots_inputs = [
            "ÙŠØ§Ù„Ù„ÙŠÙ„Ù‡ ÙŠØ§ ÙƒØ¦ÙŠØ¨Ù‡ ÙŠØ§ Ø­Ø²ÙŠÙ†Ù‡ ÙŠØ§ Ø«Ù‚ÙŠÙ„Ù‡ Ø¹Ø¯ÙŠÙŠÙŠÙŠÙŠÙŠ .",
            "Ø®Ù„ÙˆÙ†ÙŠ Ø§Ø´ÙˆÙÙƒÙ… ÙŠØ§ Ø¹ÙŠØ§Ù„ Ø§Ù„ÙƒÙ„Ø¨ ÙŠØ§ ÙˆØ¶ÙŠØ¹ÙŠÙ† ÙŠØ§ ÙÙ‚Ø± ÙØ§ÙŠØ²ÙŠÙ† Ø¨ÙƒØ£Ø³ Ø§Ù„Ù…Ù„Ùƒ ÙˆØ±Ø¨ÙŠ Ù…Ø§ ÙŠÙØµÙ„ Ø¨ÙŠÙ†Ù†Ø§ Ø§Ù„Ø§ Ø±Ø¨ Ø§Ù„Ø¹Ø¨Ø§Ø¯",
            "@USER ÙˆØ§Ù†Øª Ù…ÙŠÙ† ÙŠØ§ Ø­Ù…Ø³Ø§ÙˆÙŠ ÙŠØ§ Ø§Ø¨Ùˆ Ø£ØµÙ„ ÙˆØ§Ø·ÙŠ Ø¹Ø´Ø§Ù† ØªØ£ÙŠØ¯ ÙˆÙ„Ø§ ØªØ±ÙØ¶",
            "@USER ÙƒÙ„ Ø³Ù†Ù‡ ÙˆØ§Ù†Øª Ø·ÙŠØ¨ ÙŠØ§ Ø®Ø·ÙŠØ± ÙŠØ§ Ø§Ø®Ø·Ø± Ù…Ù‡Ø§Ø¬Ù… ÙÙŠ Ù…ØµØ± Ø§Ø±Ù…ÙŠ ÙƒÙ„ Ø­Ø§Ø¬Ø© Ù…Ù† Ø¯Ù…Ø§ØºÙƒ ÙˆØ­ØªØ´ÙˆÙ ØªÙˆÙÙŠÙ‚ Ø±Ø¨Ù†Ø§ Ù„ÙŠÙƒ",
            "@USER Ø§Ù„ÙƒØ±Ø¯ÙŠ Ù…Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù†ØµØ±ÙŠØ© Ø§Ù„Ø¨ØºÙŠØ¶Ø© ÙŠØ§ Ù…Ø²ÙˆØ±ÙŠÙ† ÙŠØ§ ÙƒØ§Ø±Ù‡ÙŠ Ø¯ÙŠÙ† Ø§Ù„Ù„Ù‡ ÙŠØ§ Ø¹Ø¨ÙŠØ¯ Ø§ØªØ§ØªÙˆØ±Ùƒ"
        ]
        shots_outputs = ["0", "1", "1", "0", "1"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shots_inputs[i] + "\n\n" + self.a_head + "<answer>" + shots_outputs[i] + "</answer>\n\n"

        for text, label in zip(inputs, outputs):
            text = self.prompt_template.format(examples, text, label if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_sentiment(self, data):
        inputs = data["text"]
        outputs = data["label"]
        texts = []
        
        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(inputs), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + inputs[i] + "\n\n" + self.a_head + "<answer>" + str(outputs[i]) + "</answer>\n\n"

        examples = ""
        shot_inputs = [
            "Ø§Ø­ÙŠØ§Ù†Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„ÙØ´Ù„ Ø¯Ø§ÙØ¹ Ù„Ù„Ù†Ø¬Ø§Ø­",
            "Ø§Ø°Ø§ Ø´Ø¹Ø±Øª Ø¨Ø´ÙŠØ¡ Ù…Ù† Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø­Ø¨Ø§Ø· ÙˆØ§Ù„Ù…Ù„Ù„ ÙØ¬Ø±Ù‘Ø¨ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ØªØ·ÙˆØ¹ÙŠ",
            "Ø§Ø°Ø§ ÙƒÙ†Ù‘Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¹Ù„Ù‰ Ù…ÙˆØ¹Ø¯ Ù…Ø¹ Ø±ÙØ¹ Ù„Ø§Ø³Ø¹Ø§Ø± Ø§Ù„Ø®Ø¨Ø² ÙƒÙ…Ø§ ÙŠØ´Ø§Ø¹ØŒ ÙØ§Ù„Ø§ÙˆÙ„Ù‰ Ø¨Ø§Ù„Ø­ÙƒÙˆÙ…Ù‡ Ø§ÙˆÙ„Ø§ Ø§Ù† ØªÙ‚ÙˆÙ… Ø¨ØªØ±Ø´ÙŠØ¯ Ø§Ù„Ø¯Ø¹Ù… Ø¨Ø­ÙŠØ« ÙŠØ°Ù‡Ø¨ ÙÙ‚Ø· Ù„Ù…Ù† ÙŠØ³ØªØ­Ù‚Ù‡!",
            "Ø§Ø±Ø­Ù…ÙˆÙ†Ø§ ØµØ±Ù†Ø§ Ù†ØµÙ Ø§Ù„Ø³ÙŠØ§Ø±Ù‡ Ù†Ø·Ù„Ø¹ Ø¨Ø§Ù„Ø¨Ø§Øµ Ø­Ø±Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…",
            "Ø§Ù„Ø§Ø¹ØªØ¯Ø§Ø¡Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† ÙˆØ§Ù„Ø§Ø·Ø¨Ø§Ø¡ ... Ø¬Ø±Ø§Ø¦Ù… Ù„Ø§ ØªÙ‚Ø¨Ù„ Ø§ÙŠ ØªØ¨Ø±ÙŠØ±"
        ]
        shots_outputs = ["1", "1", "0", "0", "0"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shot_inputs[i] + "\n\n" + self.a_head + "<answer>" + shots_outputs[i] + "</answer>\n\n"

        for text, label in zip(inputs, outputs):
            text = self.prompt_template.format(examples, text, label if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}
        

    # def format_prompt_diacratization(self, data):
    #     inputs = data["text"]
    #     outputs = data["diacratized"]
    #     texts = []

    #     examples = ""

    #     for text, diacratized in zip(inputs, outputs):
    #         text = self.prompt_template.format(examples, text, diacratized if not self.test_mode else "") + self.EOS_TOKEN
    #         texts.append(text)
        
    #     return {"text": texts}

    # def format_prompt_mcq(self, data):
    #     question = data["Question"]
    #     A, B, C, D = data["A"], data["B"], data["C"], data["D"]
    #     answers = data["answer"]
    #     texts = []

    #     examples = ""
    #     if self.shots > 0:
    #         examples = "EXAMPLES:\n" if self.lang == "en" else "Ø£Ù…Ø«Ù„Ø©:\n"
    #         indices = np.random.choice(len(question), self.shots, replace=False)
    #         for i in indices:
    #             examples += f"Example Question:" if self.lang == "en" else "Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø«Ø§Ù„:"
    #             examples += question[i] + "\n" + A[i] + "\n" + B[i] + "\n" + C[i] + "\n" + D[i] + "\n<answer>" + answers[i] + "</answer>\n\n"

    #     for question, a, b, c, d, answer in zip(question, A, B, C, D, answers):
    #         text = self.prompt_template.format(examples, question+"\n"+a+"\n"+b+"\n"+c+"\n"+d, answer if not self.test_mode else "") + self.EOS_TOKEN
    #         texts.append(text)

    #     return {"text": texts}

    def format_prompt_postagging(self, data):
        pos_tag_classes = [ "NOUN", "PUNCT", "ADP", "NUM", "SYM", "SCONJ", "ADJ", "PART", "DET", "CCONJ", "PROPN", "PRON", "X", "ADV", "INTJ", "VERB", "AUX"]

        tokenized_sents = data["tokens"]
        tags = data["upos"]
        texts = []

        outputs = []
        for i in range(len(tokenized_sents)):
            tokens = tokenized_sents[i]
            pos_tags = tags[i]

            output = ""
            for j in range(len(tokens)):
                output += tokens[j]+":"+pos_tag_classes[pos_tags[j]-1]+"\n"

            outputs.append(output)
            tokenized_sents[i] = " ".join(tokenized_sents[i])

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(tokenized_sents), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + tokenized_sents[i] + "\n\n" + self.a_head + "<answer>\n" + outputs[i] + "</answer>\n\n"

        examples = ""
        shot_inputs = [
            "ÙŠØ°ÙƒØ± Ø§Ù† ØµØ§Ø­Ø¨ÙŠ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠÙ† Ø§Ù„Ø§ÙˆÙ„ ÙˆØ§Ù„Ø«Ø§Ù†ÙŠ Ùˆ Ø§Ù„Ø«Ø§Ù†ÙŠ ÙÙ‚Ø· ÙŠØªØ£Ù‡Ù„Ø§Ù† Ø§Ù„Ù‰ Ø³ÙŠØ¯Ù†ÙŠ .",
            "ÙˆØ§Ø¶Ø§Ù Ùˆ Ø£Ø¶Ø§Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù†Ù‡ Ø£Ù† Ù‡ ÙŠØ¬Ø±Ù‰ Ø­Ø§Ù„ÙŠØ§ Ø§Ù„ØªØ­Ù‚ÙŠÙ‚ Ù…Ø¹ Ù‡Ø¤Ù„Ø§Ø¡ Ø§Ù„Ø§Ø´Ø®Ø§Øµ .",
            "Ù„Ø£Ù† Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…ØµØ§Ù†Ø¹ Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø³ ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø© .",
            "ÙˆÙƒØ§Ù† Ùˆ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ø§Ù„Ø°ÙŠ Ø£Ø¹Ù„Ù†ØªÙ‡ Ø£Ø¹Ù„Ù†Øª Ù‡ Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ù‡Ùˆ 3 Ù…Ù„Ø§ÙŠÙŠÙ† Ø·Ù† .",
            "ÙˆÙ…Ù† Ùˆ Ù…Ù† Ø§Ù„Ù…Ù‚Ø±Ø± Ø§Ù† ØªØ³ØªÙ…Ø± Ù‡Ø°Ù‡ Ø§Ù„Ø§ÙŠØ§Ù… Ø­ØªÙ‰ Ø§Ù„Ø¹Ø´Ø±ÙŠÙ† Ù…Ù† Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø¬Ø§Ø±ÙŠ .",
        ]
        shot_outputs = [
            "ÙŠØ°ÙƒØ±:VERB\nØ§Ù†:SYM\nØµØ§Ø­Ø¨ÙŠ:AUX\nØ§Ù„Ù…Ø±ÙƒØ²ÙŠÙ†:AUX\nØ§Ù„Ø§ÙˆÙ„:SCONJ\nÙˆØ§Ù„Ø«Ø§Ù†ÙŠ:X\nÙˆ:DET\nØ§Ù„Ø«Ø§Ù†ÙŠ:SCONJ\nÙÙ‚Ø·:ADV\nÙŠØªØ£Ù‡Ù„Ø§Ù†:VERB\nØ§Ù„Ù‰:PUNCT\nØ³ÙŠØ¯Ù†ÙŠ:PRON\n.:NOUN\n",
            "ÙˆØ§Ø¶Ø§Ù:X\nÙˆ:DET\nØ£Ø¶Ø§Ù:VERB\nØ§Ù„ØªÙ‚Ø±ÙŠØ±:AUX\nØ§Ù†Ù‡:X\nØ£Ù†:SYM\nÙ‡:PROPN\nÙŠØ¬Ø±Ù‰:VERB\nØ­Ø§Ù„ÙŠØ§:SCONJ\nØ§Ù„ØªØ­Ù‚ÙŠÙ‚:AUX\nÙ…Ø¹:PUNCT\nÙ‡Ø¤Ù„Ø§Ø¡:PART\nØ§Ù„Ø§Ø´Ø®Ø§Øµ:AUX\n.:NOUN\nPUNCT",
            "Ù„Ø£Ù†:DET\nÙ…Ø¹Ø¸Ù…:AUX\nØ§Ù„Ù…ØµØ§Ù†Ø¹:AUX\nØ§Ù„ØªÙŠ:PART\nØ³ÙŠØªÙ…:X\nØ³:AUX\nÙŠØªÙ…:VERB\nØ¥Ù†Ø´Ø§Ø¤Ù‡Ø§:X\nØ¥Ù†Ø´Ø§Ø¡:AUX\nÙ‡Ø§:PROPN\nØ¯Ø§Ø®Ù„:PUNCT\nØ§Ù„Ù…Ù†Ø§Ø·Ù‚:AUX\nØ§Ù„Ø­Ø±Ø©:SCONJ\n.:NOUN\n",
            "ÙˆÙƒØ§Ù†:X\nÙˆ:DET\nÙƒØ§Ù†:AUX\nØ§Ù„Ù…Ø³ØªÙ‡Ø¯Ù:SCONJ\nØ§Ù„Ø°ÙŠ:PART\nØ£Ø¹Ù„Ù†ØªÙ‡:X\nØ£Ø¹Ù„Ù†Øª:VERB\nÙ‡:PROPN\nØ§Ù„Ø­ÙƒÙˆÙ…Ø©:AUX\nÙ‡Ùˆ:PROPN\n3:ADP\nÙ…Ù„Ø§ÙŠÙŠÙ†:ADP\nØ·Ù†:AUX\n.:NOUN\nPUNCT",
            "ÙˆÙ…Ù†:X\nÙˆ:DET\nÙ…Ù†:PUNCT\nØ§Ù„Ù…Ù‚Ø±Ø±:SCONJ\nØ§Ù†:SYM\nØªØ³ØªÙ…Ø±:VERB\nÙ‡Ø°Ù‡:PART\nØ§Ù„Ø§ÙŠØ§Ù…:AUX\nØ­ØªÙ‰:PUNCT\nØ§Ù„Ø¹Ø´Ø±ÙŠÙ†:ADP\nÙ…Ù†:PUNCT\nØ§Ù„Ø´Ù‡Ø±:AUX\nØ§Ù„Ø¬Ø§Ø±ÙŠ:SCONJ\n.:NOUN\nPUNCT"
        ]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shot_inputs[i] + "\n\n" + self.a_head + "<answer>\n" + shot_outputs[i] + "</answer>\n\n"

        for inp, output in zip(tokenized_sents, outputs):
            text = self.prompt_template.format(examples, inp, output if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)

        return {"text": texts}


    def format_prompt_summarization(self, data):
        X_col = "article"
        y_col = "summary"

        articles = data[X_col]
        summaries = data[y_col]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(articles), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + articles[i] + "\n\n" + self.a_head + "<answer>" + summaries[i] + "</answer>\n\n"

        examples = ""
        shot_articles = [
            "Ø£ØµØ¯Ø±Øª Ù…Ø­ÙƒÙ…Ø© Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø¬Ù…Ø¹Ø© (25 ÙŠÙ†Ø§ÙŠØ±/ ÙƒØ§Ù†ÙˆÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ 2013) Ø¹Ù‚ÙˆØ¨Ø§Øª Ù…Ø´Ø¯Ø¯Ø© Ø¶Ø¯ Ù…ÙˆØ§Ø·Ù† Ø£Ù„Ù…Ø§Ù†ÙŠ ÙˆØ¢Ø®Ø± Ù†Ù…Ø³Ø§ÙˆÙŠ Ø¨ØªÙ‡Ù…Ø© Ø§Ù„Ø§Ù†ØªÙ…Ø§Ø¡ Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©. ÙˆØ­ÙƒÙ…Øª Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø¨Ø±Ù„ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙ‡Ù… Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØŒ Ø§Ù„Ø¨Ø§Ù„Øº Ù…Ù† Ø§Ù„Ø¹Ù…Ø± 27 Ø¹Ø§Ù…Ø§Ù‹ Ø¨Ø§Ù„Ø³Ø¬Ù† Ù„Ù…Ø¯Ø© ØªØ³Ø¹Ø© Ø£Ø¹ÙˆØ§Ù…ØŒ ÙˆØ¹Ù„Ù‰ Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠØŒ Ø§Ù„Ø¨Ø§Ù„Øº Ù…Ù† Ø§Ù„Ø¹Ù…Ø± 23 Ø¹Ø§Ù…Ø§Ù‹ Ø¨Ø§Ù„Ø³Ø¬Ù† Ù„Ù…Ø¯Ø© Ø³ØªØ© Ø£Ø¹ÙˆØ§Ù… ÙˆØªØ³Ø¹Ø© Ø£Ø´Ù‡Ø±. Â  ÙˆÙˆÙÙ‚Ø§Ù‹ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØŒ ÙØ¥Ù† Ø§Ù„Ù…ØªÙ‡Ù… Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ Ù…Ù† Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠÙ† Ù„ØªÙ†Ø¸ÙŠÙ… ""Ù…Ø¬Ø§Ù‡Ø¯ÙŠ Ø·Ø§Ù„Ø¨Ø§Ù† Ø§Ù„Ø£Ù„Ù…Ø§Ù†"". ÙˆØ£Ø¯ÙŠÙ† Ø§Ù„Ù…ØªÙ‡Ù…Ø§Ù† Ø¨Ø§Ù„Ø§Ù†ØªÙ…Ø§Ø¡ Ù„ØªÙ†Ø¸ÙŠÙ… Ø¥Ø±Ù‡Ø§Ø¨ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø±Ø¬ ÙˆØªÙ„Ù‚ÙŠ ØªØ¯Ø±ÙŠØ¨Ø§Øª Ù„Ù„Ù‚ØªØ§Ù„ ÙÙŠ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø£ÙØºØ§Ù†ÙŠØ©-Ø§Ù„Ø¨Ø§ÙƒØ³ØªØ§Ù†ÙŠØ© Ø¶Ø¯ Ø¬Ù†ÙˆØ¯ Ù‚ÙˆØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© (Ø¥ÙŠØ³Ø§Ù). Â  ÙˆØ¨Ø­Ø³Ø¨ Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡ØŒ ÙÙ‚Ø¯ Ù‚Ø§Ù… Ø§Ù„Ù…ØªÙ‡Ù… Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ Ø¨Ù†Ø´Ø± Ù…Ù‚Ø§Ø·Ø¹ ÙÙŠØ¯ÙŠÙˆ ØªÙ†Ø·ÙˆÙŠ Ø¹Ù„Ù‰ ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ø®Ù„Ø§Ù„ Ù…Ø¹Ø±ÙƒØ© Ø§Ù„Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª Ø§Ù„ØªØ´Ø±ÙŠØ¹ÙŠØ© ÙÙŠ Ø£Ù„Ù…Ø§Ù†ÙŠØ§ Ø³Ù†Ø© 2009ØŒ Ù…Ù‡Ø¯Ø¯Ø§Ù‹ Ø¨Ù†Ù‚Ù„ Ø§Ù„Ø¬Ù‡Ø§Ø¯ Ø¥Ù„Ù‰ Ø£Ù„Ù…Ø§Ù†ÙŠØ§. Â  ÙˆØªÙ… Ø§Ù„Ù‚Ø¨Ø¶ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙ‡Ù… Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ ÙÙŠ Ù…Ø§Ø±Ø³/ Ø¢Ø°Ø§Ø± Ø³Ù†Ø© 2011 ÙÙŠ Ø§Ù„Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠØ© ÙÙŠÙŠÙ†Ø§ØŒ Ø«Ù… Ø£Ù„Ù‚Øª Ø§Ù„Ø³Ù„Ø·Ø§Øª ÙÙŠ Ø¨Ø±Ù„ÙŠÙ† Ø¹Ù‚Ø¨ Ø°Ù„Ùƒ Ø¨Ø´Ù‡Ø±ÙŠÙ† Ø§Ù„Ù‚Ø¨Ø¶ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙ‡Ù… Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠØŒ Ø§Ù„Ø°ÙŠ ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªÙ‡Ù… Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ ÙÙŠ Ø£ÙØºØ§Ù†Ø³ØªØ§Ù†. Â  ÙˆØ§Ù„ØªØ²Ù… Ø§Ù„Ù…ØªÙ‡Ù…Ø§Ù† Ø§Ù„ØµÙ…Øª Ø®Ù„Ø§Ù„ Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø­Ø§ÙƒÙ…Ø© Ø§Ù„ØªÙŠ Ø§Ø³ØªÙ…Ø±Øª Ø­ÙˆØ§Ù„ÙŠ Ø¹Ø§Ù…. ÙˆØ¬Ø§Ø¡ Ø­ÙƒÙ… Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø£Ù‚Ù„ Ø¨ØµÙˆØ±Ø© Ø·ÙÙŠÙØ© Ù…Ù† Ù…Ø·Ø§Ù„Ø¨ Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…. Â  ÙŠ.Ø£/ Ø¹.Øº (Ø¯ Ø¨ Ø£)",
            "Ø¯Ø¹Ø§ Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ÙØ±Ù†Ø³ÙŠ Ø¥ÙŠÙ…Ø§Ù†ÙˆÙŠÙ„ Ù…Ø§ÙƒØ±ÙˆÙ† Ø§Ù„Ù…Ù„Ùƒ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø³Ù„Ù…Ø§Ù† Ø¨Ù† Ø¹Ø¨Ø¯ Ø§Ù„Ø¹Ø²ÙŠØ² Ø¥Ù„Ù‰ Ø±ÙØ¹ Ø§Ù„Ø­ØµØ§Ø± ""ÙƒØ§Ù…Ù„Ø§"" Ø¹Ù† Ø§Ù„ÙŠÙ…Ù† Ù„Ø¥ÙŠØµØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¨Ù„Ø¯ Ø§Ù„Ø°ÙŠ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† Ø£Ø²Ù…Ø© Ø¥Ù†Ø³Ø§Ù†ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø£Ø®Ø·Ø± ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…ØŒ ÙˆÙÙ‚ Ù…Ø§ Ø£ÙƒØ¯ Ø§Ù„Ø¥Ù„ÙŠØ²ÙŠÙ‡ Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ (27 ÙƒØ§Ù†ÙˆÙ† Ø§Ù„Ø£ÙˆÙ„/Ø¯ÙŠØ³Ù…Ø¨Ø± 2017). ÙˆØ­Ø³Ø¨ Ø§Ù„Ø¥Ù„ÙŠØ²ÙŠÙ‡ ÙØ¥Ù† Ù…Ø§ÙƒØ±ÙˆÙ† Ù‚Ø§Ù„ Ù„Ù„Ù…Ù„Ùƒ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø®Ù„Ø§Ù„ Ø§ØªØµØ§Ù„ Ù‡Ø§ØªÙÙŠ Ø¨ÙŠÙ†Ù‡Ù…Ø§ ÙŠÙˆÙ… Ø§Ù„Ø£Ø­Ø¯ Ø§Ù„Ù…Ø§Ø¶ÙŠ Ø¥Ù† ÙØ±Ù†Ø³Ø§ ØªØ±Ù‰ Ø£Ù†Ù‡ ""Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø­Ù„ Ø¹Ø³ÙƒØ±ÙŠ Ù„Ù„Ù†Ø²Ø§Ø¹ ÙÙŠ Ø§Ù„ÙŠÙ…Ù†"" ÙˆØ£Ù†Ù‡ ""Ù„Ø§ Ø¨Ø¯ Ø£Ù† ÙŠØ¹ÙˆØ¯ Ø§Ù„Ø·Ø±ÙØ§Ù† Ø¥Ù„Ù‰ Ø·Ø§ÙˆÙ„Ø© Ø§Ù„Ù…ÙØ§ÙˆØ¶Ø§Øª"". ÙˆØ°ÙƒØ± Ù…Ø§ÙƒØ±ÙˆÙ† Ø¨Ø£Ù† ÙØ±Ù†Ø³Ø§ Ø£Ø¯Ø§Ù†Øª Ø§Ø·Ù„Ø§Ù‚ Ø§Ù„Ø­ÙˆØ«ÙŠÙŠÙ† ØµØ§Ø±ÙˆØ®Ø§ ØªÙ… Ø§Ø¹ØªØ±Ø§Ø¶Ù‡ ÙÙˆÙ‚ Ø§Ù„Ø±ÙŠØ§Ø¶ ÙÙŠ 19 ÙƒØ§Ù†ÙˆÙ† Ø§Ù„Ø£ÙˆÙ„/Ø¯ÙŠØ³Ù…Ø¨Ø±. ÙˆÙ‚Ø§Ù„ Ø§Ù„Ø¥Ù„ÙŠØ²ÙŠÙ‡ Ø¥Ù† Ù…Ø§ÙƒØ±ÙˆÙ† ÙˆØ§Ù„Ù…Ù„Ùƒ Ø³Ù„Ù…Ø§Ù† Ø¨Ø­Ø«Ø§ Ø£ÙŠØ¶Ø§ Ø§Ù„ÙˆØ¶Ø¹ ÙÙŠ Ø³ÙˆØ±ÙŠØ§ Ù…Ø´ÙŠØ±Ø§ Ø¥Ù„Ù‰ Ø£Ù† Ù…Ø§ÙƒØ±ÙˆÙ† Ø£ÙŠØ¯ ""Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø¹Ù…Ù„ÙŠØ© Ø¬Ù†ÙŠÙ"" Ùˆ""Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø®Ø·Ø© Ø³Ù„Ø§Ù… Ù…ØªÙˆØ§Ø²Ù†Ø© ÙˆØªØ£ÙŠÙŠØ¯ Ø§Ù„Ø­Ù„ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªØ±Ù… ÙƒÙ„ Ø£Ø·ÙŠØ§Ù Ø§Ù„Ù…Ø¬ØªÙ…Ø¹"". ÙˆØ´ÙƒØ± Ù…Ø§ÙƒØ±ÙˆÙ† Ø§Ù„Ø¹Ø§Ù‡Ù„ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ù„Ù…Ø³Ø§Ù‡Ù…ØªÙ‡ Ø¨Ù…Ø¦Ø© Ù…Ù„ÙŠÙˆÙ† ÙŠÙˆØ±Ùˆ Ù‚ÙˆØ© Ù…ÙƒØ§ÙØ­Ø© Ø§Ù„Ø¥Ø±Ù‡Ø§Ø¨ ÙÙŠ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø³Ø§Ø­Ù„ØŒ ÙÙŠ Ø­ÙŠÙ† Ø§Ù‚ØªØ±Ø­Øª Ø§Ù„Ø±ÙŠØ§Ø¶ Ø¹Ù‚Ø¯ Ø§Ø¬ØªÙ…Ø§Ø¹ Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ ÙƒØ§Ù†ÙˆÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ/ÙŠÙ†Ø§ÙŠØ± Ù‚Ø¨Ù„ Ù‚Ù…Ø© Ù„Ù„Ù…Ø§Ù†Ø­ÙŠÙ† ÙÙŠ Ø¨Ø±ÙˆÙƒØ³Ù„ ÙÙŠ Ø´Ø¨Ø§Ø·/ÙØ¨Ø±Ø§ÙŠØ±. ÙŠØ°ÙƒØ± Ø£Ù† Ù…Ø§ÙƒØ±ÙˆÙ† Ù‚Ø§Ù… Ø¨Ø²ÙŠØ§Ø±Ø© Ø®Ø§Ø·ÙØ© Ø¥Ù„Ù‰ Ø§Ù„Ø±ÙŠØ§Ø¶ ÙÙŠ ØªØ´Ø±ÙŠÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ/Ù†ÙˆÙÙ…Ø¨Ø± ÙˆØ§Ù„ØªÙ‚Ù‰ ÙˆÙ„ÙŠ Ø§Ù„Ø¹Ù‡Ø¯ Ø§Ù„Ø£Ù…ÙŠØ± Ù…Ø­Ù…Ø¯ Ø¨Ù† Ø³Ù„Ù…Ø§Ù†. ÙˆÙŠØ¹ØªØ²Ù… Ø²ÙŠØ§Ø±Ø© Ø¥ÙŠØ±Ø§Ù† ÙˆØ¥Ø³Ø±Ø§Ø¦ÙŠÙ„ ÙˆÙÙ„Ø³Ø·ÙŠÙ† ÙˆÙ„Ø¨Ù†Ø§Ù† ÙˆØ§Ù„Ø£Ø±Ø¯Ù† Ø®Ù„Ø§Ù„ Ø§Ù„Ø¹Ø§Ù… 2018.Â ÙÙŠÙ…Ø§ Ø£ÙƒØ¯ Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù…Ø§Ø¶ÙŠ Ø£Ù† Ù…ÙŠÙ†Ø§Ø¡ Ø§Ù„Ø­Ø¯ÙŠØ¯Ø© Ø³ÙŠØ¨Ù‚Ù‰ Ù…ÙØªÙˆØ­Ø§ Ù„Ø«Ù„Ø§Ø«ÙŠÙ† ÙŠÙˆÙ…Ø§ Ø£Ù…Ø§Ù… Ø´Ø­Ù†Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª ÙˆØ§Ù„Ø¨Ø¶Ø§Ø¦Ø¹ Ø§Ù„ØªÙŠ ØªÙ†Ù‚Ù„ Ø§Ù„Ø£ØºØ°ÙŠØ© ÙˆØ§Ù„ÙˆÙ‚ÙˆØ¯. Ø².Ø£.Ø¨/Ø£.Ø­ (Ø£ Ù Ø¨ØŒ Ø±ÙˆÙŠØªØ±Ø²)",
            "ÙŠÙ„ØªÙ‚ÙŠ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠ Ø²Ø¨Ø§Ø³ØªÙŠØ§Ù† ÙƒÙˆØ±ØªØ³ Ø±Ø¦ÙŠØ³ Ø­ÙƒÙˆÙ…Ø© ÙˆÙ„Ø§ÙŠØ© Ø¨Ø§ÙØ§Ø±ÙŠØ§ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ù…Ø§Ø±ÙƒÙˆØ³ Ø²ÙˆØ¯Ø± Ø§Ù„ÙŠÙˆÙ… (Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ 20 ÙŠÙˆÙ†ÙŠÙˆ/ Ø­Ø²ÙŠØ±Ø§Ù† 2018) ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ù„ÙŠÙ†ØªØ³ Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠØ© Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø³ÙŠØ§Ø³Ø© Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù„Ø§Ø¬Ø¦ÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø´ØªØ±ÙƒØ© Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø³Ø§ ÙˆØ¨Ø§ÙØ§Ø±ÙŠØ§. ÙˆÙŠØ£ØªÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù„Ù‚Ø§Ø¡ØŒ Ø§Ù„Ù…Ø®Ø·Ø· Ù„Ù‡ Ù…Ù†Ø° Ø´Ù‡ÙˆØ±ØŒ ÙÙŠ Ø®Ø¶Ù… Ø¬Ø¯Ù„ Ø­Ø§Ø¯ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø­ÙˆÙ„ Ø±Ø¯ Ù„Ø§Ø¬Ø¦ÙŠÙ† Ù…Ù† Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¯ÙˆØ¯. ÙˆÙŠØ·Ø§Ù„Ø¨ ÙƒÙˆØ±ØªØ³ ÙˆØ²ÙˆØ¯Ø± ÙƒÙ…Ø§ ÙˆØ²ÙŠØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ (Ù‡ÙˆØ±Ø³Øª Ø²ÙŠÙ‡ÙˆÙØ± Ø§Ù„Ù…Ù†ØªÙ…ÙŠ Ø£ÙŠØ¶Ø§ Ù„Ù„Ø­Ø²Ø¨ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø³ÙŠØ­ÙŠ Ø§Ù„Ø¨Ø§ÙØ§Ø±ÙŠ) Ø¨Ø§ØªØ¨Ø§Ø¹ Ù†Ù‡Ø¬ Ù…ØªØ´Ø¯Ø¯ ÙÙŠ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù„Ø¬ÙˆØ¡. ÙˆÙŠØ°ÙƒØ± Ø£Ù† Ù…Ø§Ø±ÙƒÙˆØ³ Ø²ÙˆØ¯Ø± Ø§Ù†ØªÙ‚Ø¯ Ø®Ø·Ø· Ø§Ù„Ù…Ø³ØªØ´Ø§Ø±Ø© Ù…ÙŠØ±ÙƒÙ„ ÙˆØ§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„ÙØ±Ù†Ø³ÙŠ Ù…Ø§ÙƒØ±ÙˆÙ† Ø¨Ø´Ø£Ù† ÙˆØ¶Ø¹ Ù…ÙˆØ§Ø²Ù†Ø© Ø®Ø§ØµØ© Ø¨Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙŠÙˆØ±Ùˆ. ÙˆÙ‚Ø§Ù„ Ø²ÙˆØ¯Ø±ØŒ Ø§Ù„Ù…Ù†ØªÙ…ÙŠ Ù„Ù„Ø­Ø²Ø¨ Ø§Ù„Ù…Ø³ÙŠØ­ÙŠ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ø§Ù„Ø¨Ø§ÙØ§Ø±ÙŠØŒ Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨ÙŠÙ„ Ù„Ù‚Ø§Ø¦Ù‡ Ø¨Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠ ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ù„ÙŠÙ†ØªØ³ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© ""Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ù„Ø¢Ù† Ø·Ø±Ø­ Ù…ÙˆØ²Ø§Ù†Ø§Øª Ù…ÙˆØ§Ø²ÙŠØ© Ø¥Ø¶Ø§ÙÙŠØ©ØŒ Ø£Ùˆ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ®ÙÙŠÙ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„Ø©"". ÙˆØ­Ø°Ø± Ø²ÙˆØ¯Ø± Ù…ÙŠØ±ÙƒÙ„ Ù…Ù† Ø§Ù„Ø®Ù„Ø· Ø¨ÙŠÙ† Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù„Ø¬ÙˆØ¡ ÙˆØ§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠØ©ØŒ Ù…Ø¶ÙŠÙØ§ Ø£Ù†Ù‡ Ù„Ø§ ÙŠØ¬ÙˆØ² Ø£Ù† ØªØ­Ø§ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø±Ø© ØªØ­ÙÙŠØ² Ø¯ÙˆÙ„ Ø£ÙˆØ±ÙˆØ¨ÙŠØ© Ø£Ø®Ø±Ù‰ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø§ÙˆÙ† ÙÙŠ Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù„Ø¬ÙˆØ¡ Ø¹Ø¨Ø± ØªØ¹Ù‡Ø¯Ø§Øª Ù…Ø§Ù„ÙŠØ©ØŒ ÙˆÙ‚Ø§Ù„ ""Ø§Ù„Ø£Ù…Ø±Ø§Ù† ÙÙŠ Ù…Ø¬Ø§Ù„ÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†. Ù‡Ù†Ø§Ùƒ Ø­Ø§Ø¬Ø© Ù„Ù…Ø¨Ø¯Ø£ ÙˆØ§Ø¶Ø­ Ù„Ø¯ÙˆÙ„Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†"". ÙˆØ°ÙƒØ± Ø²ÙˆØ¯Ø± Ø£Ù† Ø­Ø²Ø¨Ù‡ ÙŠØ·Ø§Ù„Ø¨ Ø¨Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù„Ø¬Ù†Ø© Ø§Ù„Ø§Ø¦ØªÙ„Ø§Ù Ø§Ù„Ø­Ø§ÙƒÙ… Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±. ÙˆØ§ØªÙÙ‚Øª Ù…ÙŠØ±ÙƒÙ„ ÙˆÙ…Ø§ÙƒØ±ÙˆÙ† Ø£Ù…Ø³ Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡ Ø®Ù„Ø§Ù„ Ù„Ù‚Ø§Ø¦Ù‡Ù…Ø§ ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ù…ÙŠØ³Ø¨Ø±Øº Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø¹Ù„Ù‰ ÙˆØ¶Ø¹ Ù…ÙˆØ§Ø²Ù†Ø© Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙŠÙˆØ±Ùˆ ÙÙŠ Ø¥Ø·Ø§Ø± Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©ØŒ Ù„ÙƒÙ† Ø¯ÙˆÙ† Ø¥Ø¹Ø·Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù† Ù…Ù‚Ø¯Ø§Ø± Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù„Ù„Ø¹Ø§Ù… 2021 ÙˆØªÙ‡Ø¯Ù Ù…ÙŠØ±ÙƒÙ„ ÙˆÙ…Ø§ÙƒØ±ÙˆÙ† Ù…Ù† Ø°Ù„Ùƒ Ø¥Ù„Ù‰ Ø¬Ø¹Ù„ Ø§Ù„ÙŠÙˆØ±Ùˆ Ø£ÙƒØ«Ø± Ù…Ù‚Ø§ÙˆÙ…Ø© Ù„Ù„Ø£Ø²Ù…Ø§ØªØŒ ÙˆØ¶Ø® Ø§Ø³ØªØ«Ù…Ø§Ø±Ø§Øª Ø¨Ø§Ù„Ù…Ù„ÙŠØ§Ø±Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©. ØªØ¬Ø¯Ø± Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„Ø­Ø²Ø¨ Ø§Ù„Ø¨Ø§ÙØ§Ø±ÙŠ Ø£Ù…Ù‡Ù„ Ù…ÙŠØ±ÙƒÙ„ Ø­ØªÙ‰ Ù†Ù‡Ø§ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø± Ù„Ù„ØªÙˆØµÙ„ Ø¥Ù„Ù‰ Ø§ØªÙØ§Ù‚ Ø£ÙˆØ±ÙˆØ¨ÙŠ Ø­ÙˆÙ„ Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù„Ø¬ÙˆØ¡. ÙˆÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… ØªÙ…ÙƒÙ† Ù…ÙŠØ±ÙƒÙ„ Ù…Ù† ØªØ­Ù‚ÙŠÙ‚ Ø°Ù„ÙƒØŒ ÙŠØ¹ØªØ²Ù… ÙˆØ²ÙŠØ± Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù‡ÙˆØ±Ø³Øª Ø²ÙŠÙ‡ÙˆÙØ± Ø¹Ø¯Ù… Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ø§Ø¬Ø¦ÙŠÙ† Ø§Ù„Ù…Ø³Ø¬Ù„ÙŠÙ† ÙÙŠ Ø¯ÙˆÙ„ Ø£Ø®Ø±Ù‰ Ø¨Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠ Ø¨Ø¹Ø¨ÙˆØ± Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©. Ø­.Ø²/ Ù….Ø³Â (Ø¯.Ø¨.Ø£)",
            "Ù…Ø«Ù„ Ø«Ù„Ø§Ø«Ø© Ø£Ø´Ø®Ø§ØµÂ ÙŠØ´ØªØ¨Ù‡ Ø¨Ø£Ù†Ù‡Ù… Ù…Ù† Ø§Ù„Ù…ØªØ´Ø¯Ø¯ÙŠÙ† Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙˆÙŠÙŠÙ† Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø®Ù…ÙŠØ³ (Ø§Ù„ØªØ§Ø³Ø¹ Ù…Ù† ØªØ´Ø±ÙŠÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ/Ù†ÙˆÙÙ…Ø¨Ø± 2017) Ø£Ù…Ø§Ù… Ù…Ø­ÙƒÙ…Ø© ÙÙŠ Ù…Ø¯ÙŠÙ†Ø© Ù…ÙŠÙˆÙ†ÙŠØ® Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø®Ù„ÙÙŠØ© ØªÙ‡Ù… ØªØªØ¹Ù„Ù‚ Ø¨Ø¯Ø¹Ù…Ù‡Ù… ""Ù„Ù…Ù†Ø¸Ù…Ø© Ø¥Ø±Ù‡Ø§Ø¨ÙŠØ© Ø£Ø¬Ù†Ø¨ÙŠØ©"" ÙÙŠ Ø³ÙˆØ±ÙŠØ§. ÙˆÙ‚Ø§Ù„ ÙÙ„ÙˆØ±ÙŠØ§Ù† Ø¬Ù„ÙŠÙØªØ³ÙƒÙŠ Ø§Ù„Ù…ØªØ­Ø¯Ø« Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ø¹Ù„ÙŠØ§ ÙÙŠ Ù…ÙŠÙˆÙ†ÙŠØ® Ø¥Ù† Ø§Ù„Ù…ØªÙ‡Ù…ÙŠÙ† ÙŠØ¹ØªÙ‚Ø¯ Ø¨Ø£Ù†Ù‡Ù… ""Ø£Ù…Ø¯ÙˆØ§ (Ø¬Ù…Ø§Ø¹Ø©) Ø¬Ù†Ø¯ Ø§Ù„Ø´Ø§Ù… Ø¨Ø³ÙŠØ§Ø±Ø© Ø¥Ø³Ø¹Ø§Ù ÙˆÙ…Ø±ÙƒØ¨Ø§Øª Ø£Ø®Ø±Ù‰ Ø¹Ø§Ù… 2013"". ÙˆØªØ¨Ù„Øº Ø£Ø¹Ù…Ø§Ø±Ù‡Ù… Ø¨ÙŠÙ† Ø§Ù„Ù€30 Ùˆ38 Ø¹Ø§Ù…Ø§Ù‹. ÙˆÙŠÙ†Ø­Ø¯Ø± Ø§Ø«Ù†Ø§Ù† Ù…Ù†Ù‡Ù… Ù…Ù† Ø§Ù„Ø¨ÙˆØ³Ù†Ø© ÙˆØ§Ù„Ù‡Ø±Ø³Ùƒ ÙˆÙŠØ­Ù…Ù„ Ø§Ù„Ø«Ø§Ù„Ø« Ø§Ù„Ø¬Ù†Ø³ÙŠØ© Ø§Ù„ÙƒÙˆØ³ÙˆÙÙŠØ©. ÙˆÙ‚Ø§Ù„Øª Ù…ØµØ§Ø¯Ø± Ù‚Ø¶Ø§Ø¦ÙŠØ© Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø¥Ù† Ø¬Ù†Ø¯ Ø§Ù„Ø´Ø§Ù… Ø¬Ù…Ø§Ø¹Ø© Ù…Ù† Ø£ØµÙ„ Ø´ÙŠØ´Ø§Ù†ÙŠ ØªØ³Ø¹Ù‰ Ù„ØªØ£Ø³ÙŠØ³ Ø®Ù„Ø§ÙØ© Ø¥Ø³Ù„Ø§Ù…ÙŠØ© ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©. ÙˆÙŠØµÙÙ‡Ø§ Ø§Ù„Ù…Ø¹Ù‡Ø¯ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ Ù„Ù„Ø´Ø¤ÙˆÙ† Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ù„Ø£Ù…Ù†ÙŠØ© Ø¨Ø£Ù†Ù‡Ø§ Ø¬Ù…Ø§Ø¹Ø© Ø­Ø§ØµÙ„Ø© Ø¹Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ Ø¬ÙŠØ¯ Ø¯Ø£Ø¨Øª Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø§ÙˆÙ† Ù…Ø¹ Ø¬Ø¨Ù‡Ø© Ø§Ù„Ù†ØµØ±Ø© Ø§Ù„ÙØ±Ø¹ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© ÙÙŠ Ø³ÙˆØ±ÙŠØ§. ÙˆÙÙŠ Ø³ÙŠØ§Ù‚ Ù…Ù†ÙØµÙ„ØŒ ÙˆØ¬Ù‡Øª Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ø¹Ù„ÙŠØ§ ÙÙŠ Ø´ØªÙˆØªØºØ§Ø±Øª ØªÙ‡Ù…Ø© Ø§Ø±ØªÙƒØ§Ø¨ Ø¬Ø±Ø§Ø¦Ù… Ø­Ø±Ø¨ Ù„Ø¬Ù†Ø¯ÙŠ Ø³Ø§Ø¨Ù‚ ÙÙŠ Ø§Ù„Ø¬ÙŠØ´ Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ. ÙˆØ­Ø³Ø¨ Ø§Ù„Ù…Ø­ÙƒÙ…Ø© ÙÙ‚Ø¯ Ø¹ÙØ«Ø± ÙÙŠ Ù‡Ø§ØªÙ Ø§Ù„Ø¬Ù†Ø¯ÙŠ Ø¹Ù„Ù‰ ØµÙˆØ± ØªØ¸Ù‡Ø±Ù‡ ÙˆÙ‡Ùˆ Ø­Ø§Ù…Ù„Ø§Ù‹ Ø±Ø£Ø³ Ù…Ù‚Ø·ÙˆØ¹ Ù„Ø¥Ø±Ù‡Ø§Ø¨ÙŠ. ÙˆÙŠØ¨Ù„Øº Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ Ù…Ù† Ø§Ù„Ø¹Ù…Ø± 24 Ø¹Ø§Ù…Ø§Ù‹. ÙˆØ­Ø³Ø¨ Ø§Ù„Ù…Ø­ÙƒÙ…Ø© ÙÙ‚Ø¯ Ù‡Ø¯Ø¯ Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ Ù„Ø§Ø¬Ø¦ Ø£ÙØºØ§Ù†ÙŠ Ø¨Ø§Ù„Ù‚ØªÙ„Ø› Ø¥Ø° Ø¹Ø±Ø¶ Ø¹Ù„ÙŠÙ‡ Ø§Ù„ØµÙˆØ± ÙÙŠ Ù‡Ø§ØªÙÙ‡ Ù‚Ø§Ø¦Ù„Ø§Ù‹: ""Ø³Ø£ÙØ¹Ù„ Ø¨Ùƒ ÙƒÙ…Ø§ ÙØ¹Ù„Øª Ø¨Ø¥Ø±Ù‡Ø§Ø¨ÙŠ Ø¯Ø§Ø¹Ø´"". Ø®.Ø³/Ø­.Ø¹.Ø­ (Ø±ÙˆÙŠØªØ±Ø²ØŒ Ø¯ Ø¨ Ø£)",
            "ØªÙˆØ¬Ù‡ Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø¨Ù†ÙŠØ§Ù…ÙŠÙ† Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø£Ø­Ø¯ Ø¥Ù„Ù‰ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© ÙÙŠ Ø²ÙŠØ§Ø±Ø© ÙŠØ³ØªÙ‚Ø¨Ù„Ù‡ Ø®Ù„Ø§Ù„Ù‡Ø§ Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ø¨Ø§Ø±Ø§Ùƒ Ø£ÙˆØ¨Ø§Ù…Ø§ ÙÙŠ Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø£Ø¨ÙŠØ¶ ØºØ¯Ø§ (Ø§Ù„ØªØ§Ø³Ø¹ Ù…Ù† Ù†ÙˆÙÙ…Ø¨Ø±/ØªØ´Ø±ÙŠÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ 2015). ÙˆØ³ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù„Ù‚Ø§Ø¡ Ø§Ù„Ø£ÙˆÙ„ Ø¨ÙŠÙ†Ù‡Ù…Ø§ Ù…Ù†Ø° ØªÙˆÙ‚ÙŠØ¹ Ø§Ù„Ø§ØªÙØ§Ù‚ Ø§Ù„Ù†ÙˆÙˆÙŠ Ø¨ÙŠÙ† Ø¥ÙŠØ±Ø§Ù† ÙˆØ§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø³Øª Ø§Ù„ÙƒØ¨Ø±Ù‰. ÙˆÙˆÙÙ‚Ø§ Ù„Ù„Ø¥Ø°Ø§Ø¹Ø© Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØ©ØŒ ÙÙ‚Ø¯ Ø£Ø¹Ø±Ø¨Øª Ø¯ÙˆØ§Ø¦Ø± Ø±Ø³Ù…ÙŠØ© Ø¹Ù† Ø§Ù„Ø£Ù…Ù„ ÙÙŠ Ø£Ù† ØªÙØªØ­ Ù‡Ø°Ù‡ Ø§Ù„Ø²ÙŠØ§Ø±Ø© ØµÙØ­Ø© Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠÙ†. ÙˆÙŠØªÙˆÙ‚Ø¹ Ø£Ù† ØªØªÙ…Ø­ÙˆØ± Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø¨ÙŠÙ† Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ ÙˆØ£ÙˆØ¨Ø§Ù…Ø§ Ø­ÙˆÙ„ ""Ø­Ø²Ù…Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„ØªÙŠ Ø³ØªÙ‚Ø¯Ù…Ù‡Ø§ Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„""ØŒ ÙˆÙƒØ°Ù„Ùƒ ""Ø§Ù†Ø¹Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø³ÙŠØ§Ø³ÙŠ Ù…Ø¹ Ø§Ù„Ø·Ø±Ù Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠ"". ÙˆØ°ÙƒØ±Øª Ø§Ù„Ø¥Ø°Ø§Ø¹Ø© Ø£Ù† Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ ÙŠØ³Ø¹Ù‰ Ø¥Ù„Ù‰ Ø·Ø±Ø­ Ù…Ø³Ø£Ù„Ø© Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù…Ù†Ø´Ø¢Øª Ø§Ù„Ù†ÙˆÙˆÙŠØ© Ø§Ù„Ø¥ÙŠØ±Ø§Ù†ÙŠØ© Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØµÙ„ Ø¥Ù„Ù‰ ØªÙØ§Ù‡Ù…Ø§Øª Ø¨Ø´Ø£Ù† ØªØ¨Ø§Ø¯Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¨Ø§Ø±ÙŠØ© Ù…Ø¹ ÙˆØ§Ø´Ù†Ø·Ù† Ø¨Ø®ØµÙˆØµ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¥ÙŠØ±Ø§Ù†ÙŠ. ÙˆØ°ÙƒØ±Øª ØµØ­ÙŠÙØ© Ù‡Ø§Ø¢Ø±ØªØ³ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠØ© Ø§Ù„ÙŠÙˆÙ… Ø§Ù„Ø£Ø­Ø¯ Ø£Ù† Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø³ÙŠØ¹Ø±Ø¶ Ø®Ù„Ø§Ù„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ Ø­Ø²Ù…Ø© Ù…Ù† Ø¨ÙˆØ§Ø¯Ø± Ø­Ø³Ù† Ù†ÙŠØ© ØªØ¬Ø§Ù‡ Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠÙŠÙ† ÙÙŠ Ø§Ù„Ø¶ÙØ© Ø§Ù„ØºØ±Ø¨ÙŠØ© ÙˆÙ‚Ø·Ø§Ø¹ ØºØ²Ø©. Ùˆ.Ø¨/Ù….Ø³ (Ø¯.Ø¨.Ø£)"
        ]
        shot_summaries = [
            "Ø£ØµØ¯Ø±Øª Ù…Ø­ÙƒÙ…Ø© Ø£Ù„Ù…Ø§Ù†ÙŠØ© Ø£Ø­ÙƒØ§Ù…Ø§Ù‹ Ù…Ø´Ø¯Ø¯Ø© Ø¨Ø­Ù‚ Ø£Ù„Ù…Ø§Ù†ÙŠ ÙˆÙ†Ù…Ø³Ø§ÙˆÙŠ Ø¨ØªÙ‡Ù…Ø© Ø§Ù†ØªÙ…Ø§Ø¦Ù‡Ù…Ø§ Ø¥Ù„Ù‰ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© ÙˆØªÙ„Ù‚ÙŠ ØªØ¯Ø±ÙŠØ¨Ø§Øª Ù‚ØªØ§Ù„ÙŠØ© ÙÙŠ Ø£Ø­Ø¯ Ù…Ø¹Ø³ÙƒØ±Ø§ØªÙ‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø¨ÙŠÙ† Ø£ÙØºØ§Ù†Ø³ØªØ§Ù† ÙˆØ¨Ø§ÙƒØ³ØªØ§Ù†. Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø¬Ø§Ø¡Øª Ø£Ù‚Ù„ Ù…Ù…Ø§ Ø·Ø§Ù„Ø¨ Ø¨Ù‡ Ø§Ù„Ø§Ø¯Ø¹Ø§Ø¡ Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠ.",
            "ÙƒØ´ÙØª Ø§Ù„Ø±Ø¦Ø§Ø³Ø© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© Ø£Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ Ù…Ø§ÙƒØ±ÙˆÙ† Ø·Ø§Ù„Ø¨ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¨Ø±ÙØ¹ Ø§Ù„Ø­ØµØ§Ø± ""ÙƒØ§Ù…Ù„Ø§"" Ø¹Ù† Ø§Ù„ÙŠÙ…Ù† Ù„Ø¥ÙŠØµØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø§Øª Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ÙŠØ©. ÙƒÙ…Ø§ Ø´Ø¯Ø¯ Ù…Ø§ÙƒØ±ÙˆÙ† Ø¹Ù„Ù‰ Ø£Ù†Ù‡ ""Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø­Ù„ Ø¹Ø³ÙƒØ±ÙŠ Ù„Ù„Ù†Ø²Ø§Ø¹ ÙÙŠ Ø§Ù„ÙŠÙ…Ù†"" ÙˆØ£Ù†Ù‡ ""Ù„Ø§ Ø¨Ø¯ Ø£Ù† ÙŠØ¹ÙˆØ¯ Ø§Ù„Ø·Ø±ÙØ§Ù† Ø¥Ù„Ù‰ Ø·Ø§ÙˆÙ„Ø© Ø§Ù„Ù…ÙØ§ÙˆØ¶Ø§Øª"".",
            "Ù…ÙˆØ§Ø²Ø§Ø© Ù…Ø¹ Ø§Ù„Ø¬Ù‡ÙˆØ¯ Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ù„Ù‡Ø§ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø±Ø© Ø£Ù†ØºÙŠÙ„Ø§ Ù…ÙŠØ±ÙƒÙ„ Ø¨Ø´Ø£Ù† Ø¨Ù„ÙˆØ±Ø© Ø³ÙŠØ§Ø³Ø© Ø£ÙˆØ±ÙˆØ¨ÙŠØ© Ù„Ù„Ø¬ÙˆØ¡ØŒ ÙŠÙ„ØªÙ‚ÙŠ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù†Ù…Ø³Ø§ÙˆÙŠ Ø¨Ø±Ø¦ÙŠØ³ ÙˆÙ„Ø§ÙŠØ© Ø¨Ø§ÙØ§Ø±ÙŠØ§ Ù…Ù† Ø§Ù„Ø­Ø²Ø¨ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø³ÙŠØ­ÙŠ Ø§Ù„Ù…Ø·Ø§Ù„Ø¨ Ø¨ØªØ´Ø¯ÙŠØ¯ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù„Ø¬ÙˆØ¡ ÙÙŠÙ…Ø§ ÙŠØ´Ø¨Ù‡ ØªØ­Ø¯ÙŠØ§ Ù„Ù„Ù…Ø³ØªØ´Ø§Ø±Ø© Ù…ÙŠØ±ÙƒÙ„.",
            "ÙˆØ¬Ù‡Øª Ù…Ø­ÙƒÙ…Ø© ÙÙŠ Ù…ÙŠÙˆÙ†Ø® ØªÙ‡Ù…Ø© Ø¯Ø¹Ù… Ù…Ù†Ø¸Ù…Ø© Ø¥Ø±Ù‡Ø§Ø¨ÙŠØ© ÙÙŠ Ø³ÙˆØ±ÙŠØ§ Ù„Ø«Ù„Ø§Ø«Ø© Ø£Ø´Ø®Ø§Øµ ÙŠØ´ØªØ¨Ù‡ Ø¨Ø£Ù†Ù‡Ù… Ù…Ù† Ø§Ù„Ù…ØªØ´Ø¯Ø¯ÙŠÙ† Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙˆÙŠÙŠÙ†. ÙƒÙ…Ø§ ÙˆØ¬Ù‡Øª Ù…Ø­ÙƒÙ…Ø© Ø£Ø®Ø±Ù‰ ÙÙŠ Ø´ØªÙˆØªØºØ§Ø±Øª ØªÙ‡Ù…Ø© Ø§Ø±ØªÙƒØ§Ø¨ Ø¬Ø±Ø§Ø¦Ù… Ø­Ø±Ø¨ Ù„Ø¬Ù†Ø¯ÙŠ Ø³Ø§Ø¨Ù‚ ÙÙŠ Ø§Ù„Ø¬ÙŠØ´ Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠ.",
            "ÙŠÙ‚ÙˆÙ… Ø±Ø¦ÙŠØ³ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ÙŠ Ø¨Ù†ÙŠØ§Ù…ÙŠÙ† Ù†ØªÙ†ÙŠØ§Ù‡Ùˆ Ø¨Ø²ÙŠØ§Ø±Ø© Ø¥Ù„Ù‰ ÙˆØ§Ø´Ù†Ø·Ù†ØŒ ÙŠØ¬ØªÙ…Ø¹ Ø¨Ù‡Ø§ Ø¨Ø§Ù„Ø±Ø¦ÙŠØ³ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ Ù„Ø£ÙˆÙ„ Ù…Ø±Ø© Ù…Ù†Ø° Ø§Ù„ØªÙˆÙ‚ÙŠØ¹ Ø¹Ù„Ù‰ Ø§Ù„Ø§ØªÙØ§Ù‚ Ø§Ù„Ù†ÙˆÙˆÙŠ Ø§Ù„Ø¥ÙŠØ±Ø§Ù†ÙŠ. ÙˆÙ…Ù† Ø§Ù„Ù…Ù†ØªØ¸Ø± Ø£Ù† ÙŠØ­Ù…Ù„ Ù…Ø¹Ù‡ Ù†ØªØ§Ù†ÙŠØ§Ù‡Ùˆ Ø±Ø²Ù…Ø© Ù…Ù† Ø¨ÙˆØ§Ø¯Ø± Ø­Ø³Ù† Ø§Ù„Ù†ÙŠØ© Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ÙÙ„Ø³Ø·ÙŠÙ†ÙŠÙŠÙ†."
        ]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shot_articles[i] + "\n\n" + self.a_head + "<answer>" + shot_summaries[i] + "</answer>\n\n"

        for article, summary in zip(articles, summaries):
            text = self.prompt_template.format(examples, article, summary if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_translation(self, data):
        sourceStrings = data["sourceString"]
        targetStrings = data["targetString"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(sourceStrings), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + sourceStrings[i] + "\n\n" + self.a_head + "<answer>" + targetStrings[i] + "</answer>\n\n"

        examples = ""
        shots_sourceStrings = [
            "ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ø­ÙƒÙˆÙ…Ø§Øª Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù…Ø¹Ù†ÙŠ",
            "Ø¨Ù…Ø³Ø£Ù„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø¶Ø§Ø¡ Ø¬Ù†Ø§Ø¦ÙŠ Ø¯ÙˆÙ„ÙŠ",
            "Ù£ - Ù‚Ø¯Ù…Øª Ø§Ø³ØªØ±Ø§Ù„ÙŠØ§ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù† Ø§Ù„Ø°ÙŠ Ø£Ø¯Ù„Øª Ø¨Ù‡ ÙÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù…Ù†Ø§Ù‚Ø´Ø© Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙÙŠ Ø§Ù„Ù„Ø¬Ù†Ø© Ø§Ù„Ø³Ø§Ø¯Ø³Ø© ÙÙŠ Ù¢Ù¨ ØªØ´Ø±ÙŠÙ† Ø§ï»·ÙˆÙ„/Ø£ÙƒØªÙˆØ¨Ø± Ù¡Ù©Ù©Ù¢ØŒ ØªÙ‚ÙŠÙŠÙ…Ø§ Ù„Ù„Ù†Ù‡Ø¬ Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ø°ÙŠ ÙŠØªØ¨Ø¹Ù‡ Ø§Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù…Ù„ ÙˆØ£Ø´Ø§Ø±Øª Ø§Ù„Ù‰ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ù†Ù‡Ø¬ :",
            "ÙˆÙ…Ù† Ø§Ù„Ø¬Ù„ÙŠ Ø£Ù† Ø¹Ø¨Ø¡ Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø³ÙŠÙƒÙˆÙ† Ø£ÙŠØ¶Ø§ Ø£Ø´Ø¯ Ù…Ø­Ø¯ÙˆØ¯ÙŠØ©ØŒ Ù…ØªÙ‰ ÙƒØ§Ù†Øª Ø§Ù„Ùˆï»»ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ…Ø§Ø±Ø³Ù‡Ø§ Ù…ØªÙÙ‚Ø© Ù…Ø¹ Ùˆï»»ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø§ÙƒÙ… Ø§Ù„ÙˆØ·Ù†ÙŠØ© Ø£ÙƒØ«Ø± Ù…Ù† ÙƒÙˆÙ†Ù‡Ø§ Ùˆï»»ÙŠØ© Ø®Ø§ØµØ©.",
            "ÙˆÙŠØ¹ÙƒØ³ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆÙ‚Ù ØªÙÙ‡Ù…Ø§ Ù„Ø¹Ø¨Ø¡ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙŠ Ù‚Ø¯ ØªÙˆØ§Ø¬Ù‡Ù‡ Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ù…Ø±ØªØ¢Ø©ØŒ ÙÙŠ Ø³Ù†ÙˆØ§Øª Ø¹Ù…Ù„Ù‡Ø§ Ø§ï»·ÙˆÙ„Ù‰ Ø¹Ù„Ù‰ Ø§ï»·Ù‚Ù„ØŒ ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØªÙƒØ¨Ø¯ Ù†ØªÙŠØ¬Ø© ï»¹Ù†Ø´Ø§Ø¡ Ù…Ø­ÙƒÙ…Ø© ÙˆØ§ï»¹Ø¨Ù‚Ø§Ø¡ Ø¹Ù„ÙŠÙ‡Ø§ ÙƒÙ‡ÙŠØ¦Ø© Ù…ØªÙØ±ØºØ© ØªØ¶Ù… Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒØ§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ù‚Ø¶Ø§Ø© ÙˆÙ‡ÙŠÙƒï»» Ø¥Ø¯Ø§Ø±ÙŠØ§ Ø¯Ø§Ø¹Ù…Ø§."
        ]
        shots_targetStrings = [
            "COMMENTS OF GOVERNMENTS ON THE REPORT OF THE WORKING GROUP",
            "ON THE QUESTION OF AN INTERNATIONAL CRIMINAL JURISDICTION",
            "3. In its intervention during the debate on this issue in the Sixth Committee on 28 October 1992, Australia assessed the general approach of the Working Group and noted the importance of the following elements of that approach:",
            "he workload of a court would also clearly be more limited if it exercised concurrent jurisdiction with national courts rather than exclusive jurisdiction.",
            "This position reflects an understanding of the limited workload that a court would face, at least in its early years of operation, and the costs that would be incurred in establishing and maintaining a court on a full-time basis with a full complement of judges and a supporting administrative structure."
        ]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shots_sourceStrings[i] + "\n\n" + self.a_head + "<answer>" + shots_targetStrings[i] + "</answer>\n\n"

        for sourceString, targetString in zip(sourceStrings, targetStrings):
            text = self.prompt_template.format(examples, sourceString, targetString if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_paraphrasing(self, data):
        sentences, paraphrases = [], []

        if self.split == "test":
            temp = data["First sentence;second sentence;44_experts;similarity;parahrase"]
            for d in temp:
                d = d.split(";")
                sentences.append(d[0])
                paraphrases.append(d[1])
        else:
            sentences = data["Source"]
            paraphrases = data["Target"]

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(sentences), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + sentences[i] + "\n\n" + self.a_head + "<answer>" + paraphrases[i] + "</answer>\n\n"

        examples = ""
        shots_sentences = [
            "Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ Ù‡Ø¯ÙØŒ Ø§Ø¬Ø¹Ù„ Ù‡Ø¯ÙÙƒ Ø§Ù„Ø£ÙˆÙ„ Ù‡Ùˆ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡Ø¯Ù.",
            "Ø§Ø­Ø±Øµ Ø¹Ù„Ù‰ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø§ ØªØ­Ø¨ ÙˆØ¥Ù„Ø§ ÙØ³ÙˆÙ ØªØ¶Ø·Ø± Ø¥Ù„Ù‰ Ù‚Ø¨ÙˆÙ„ Ù…Ø§ ØªØ­ØµÙ„ Ø¹Ù„ÙŠÙ‡.",
            "Ù„Ø§ ØªÙ†Ø¸Ø± Ø¥Ù„Ù‰ ØµØºØ± Ø§Ù„Ø°Ù†Ø¨ ÙˆÙ„ÙƒÙ† Ø§Ù†Ø¸Ø± Ø¥Ù„Ù‰ Ø¹Ø¸Ù…Ø© Ù…Ù† Ø¹ØµÙŠØª.",
            "ÙÙŠ ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø­ÙŠØ§Ù† Ø¹Ù„ÙŠÙƒ Ø£Ù† ØªØªÙˆÙ‚Ø¹ Ù…Ø§ Ù‡Ùˆ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹.",
            "Ø§Ø®ØªÙ„Ø§Ù Ø§Ù„Ø¢Ø±Ø§Ø¡ Ø­ÙˆÙ„ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© ÙÙŠ Ù…ØµØ±"
        ]
        shots_paraphrases = [
            "Ø§Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù„Ø¯ÙŠÙƒ Ù‡Ø¯Ù ÙØ§Ø¬Ø¹Ù„ Ù‡Ø¯ÙÙƒ Ø§Ù„Ø§ÙˆÙ„ Ø§ÙŠØ¬Ø§Ø¯ ÙˆØ§Ø­Ø¯ .",
            "Ø§Ù‡ØªÙ… Ø¨Ø£Ù† ØªØ­ØµÙ„ Ø¹Ù„Ù‰ Ù…Ø§ ØªØ­Ø¨Ù‡ Ùˆ Ø§Ù„Ø§ Ø³ØªÙƒÙˆÙ† Ù…Ø¬Ø¨Ø±Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù† ØªÙ‚Ø¨Ù„ Ù…Ø§ ØªØ­ØµÙ„ Ø¹Ù„ÙŠÙ‡ .",
            "Ù„Ø§ ØªÙ†Ø¸Ø± Ø§Ù„Ù‰ ØµØºØ± Ø§Ù„Ø®Ø·ÙŠØ¦Ø© Ùˆ Ù„ÙƒÙ† Ø§Ù†Ø¸Ø± Ø§Ù„Ù‰ Ø¹Ø¸Ù… Ù…Ù† Ø¹ØµÙŠØª .",
            "ÙÙŠ Ø£Ø­ÙŠØ§Ù† ÙƒØ«ÙŠØ±Ø© Ø¹Ù„ÙŠÙƒ Ø§Ù† ØªØªÙˆÙ‚Ø¹ Ù…Ø§ Ù„ÙŠØ³ Ù…ØªÙˆÙ‚Ø¹Ø§Ù‹ .	",
            "ØªØ¨Ø§ÙŠÙ† Ø§Ù„Ø¢Ø±Ø§Ø¡ Ø¨Ø´Ø£Ù† Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© ÙÙŠ Ù…ØµØ±"
        ]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shots_sentences[i] + "\n\n" + self.a_head + "<answer>" + shots_paraphrases[i] + "</answer>\n\n"

        texts = []
        for sent, para in zip(sentences, paraphrases):
            text = self.prompt_template.format(examples, sent, para if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    
    def format_prompt_transliteration(self,data):
        EN = data["source"]
        AR = data["transliteration"]

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(EN), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + EN[i] + "\n\n" + self.a_head + "<answer>" + AR[i] + "</answer>\n\n"

        examples = ""
        shots_EN = [
            "Btgahzo el flat!!",
            "Enty ya benty msh btrodii 3la elbta3 da abdan",
            "2a5eraaan",
            "w stress sho3'lo",
            "enty 3amlah yom 7'ames w elnas 7trg3 mn sho3'lha w try7 w tgelk",
        ]
        shots_AR = [
            "Ø¨ØªØ¬Ù‡Ø²ÙˆØ§ Ø§Ù„ÙÙ„Øª!!",
            "Ø§Ù†ØªÙŠ ÙŠØ§ Ø¨Ù†ØªÙŠ Ù…Ø´ Ø¨ØªØ±Ø¯ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ØªØ§Ø¹ Ø¯Ù‡ Ø§Ø¨Ø¯Ø§",
            "Ø£Ø®ÙŠØ±Ø§Ù†",
            "ÙˆØ³ØªØ±Ø³ Ø´ØºÙ„Ù‡",
            "Ø§Ù†ØªÙŠ Ø¹Ù…Ù„Ø§Ù‡ ÙŠÙˆÙ… Ø®Ù…ÙŠØ³ ÙˆØ§Ù„Ù†Ø§Ø³ Ø­ØªØ±Ø¬Ø¹ Ù…Ù† Ø´ØºÙ„Ù‡Ø§ ÙˆØªØ±ÙŠØ­ ÙˆØªØ¬ÙŠ Ù„Ùƒ"
        ]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shots_EN[i] + "\n\n" + self.a_head + "<answer>" + shots_AR[i] + "</answer>\n\n"
        
        texts = []
        for en, ar in zip(EN, AR):
            text = self.prompt_template.format(examples, en, ar if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_GQA(self, data):
        question = data["question_text"]
        answer = data["answers"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(question), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + question[i] + "\n\n" + self.a_head + "<answer>" + answer[i]["text"][0] + "</answer>\n\n"

        examples = ""
        shots_question = [
            "ÙƒÙ… Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª ÙÙˆØ² Ø§Ù„Ø£ÙˆØ±ÙˆØºÙˆØ§ÙŠ Ø¨Ø¨Ø·ÙˆÙ„Ø© ÙƒØ§Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… Ù„ÙƒØ±Ùˆ Ø§Ù„Ù‚Ø¯Ù…ØŸ",
            "Ù…Ù† Ù‡Ùˆ Ù…ÙƒØªØ´Ù Ø§Ù„Ù…Ø±Ùˆ Ø£Ùˆ Ø§Ù„ÙƒÙˆØ§Ø±ØªØ² ØŸ",
            "ÙƒÙŠÙ ÙŠØªØµÙ„ Ø§Ù„Ø¬Ù†ÙŠÙ† Ø¨Ø§Ù„Ø±Ø­Ù… ØŸ",
            "Ø£ÙŠÙ† ÙŠÙ‚Ø¹ Ù…Ø³Ø¬Ø¯ Ø§Ù„Ø³Ù„Ø·Ø§Ù† Ø¹Ø¨Ø¯ Ø§Ù„Ù…Ø¬ÙŠØ¯ØŸ",
            "Ù…Ø§ Ø¹Ø§ØµÙ…Ø© Ø¬ÙˆØ±Ø¬ÙŠØ§ØŸ"
        ]
        shots_answer = [
            "['Ø¨Ø·ÙˆÙ„ØªÙŠÙ†', 'Ø¨Ø·ÙˆÙ„ØªÙŠÙ†']",
            "['Ø§Ù„ÙØ±Ù†Ø³ÙŠ (Ø¨ÙŠÙŠØ± ÙƒÙˆØ±ÙŠ) ÙˆØ£Ø®ÙˆÙ‡ (Ø¬Ø§Ùƒ)', '(Ø¨ÙŠÙŠØ± ÙƒÙˆØ±ÙŠ) ÙˆØ£Ø®ÙˆÙ‡ (Ø¬Ø§Ùƒ)', 'Ø¨ÙŠÙŠØ± ÙƒÙˆØ±ÙŠ) ÙˆØ£Ø®ÙˆÙ‡ (Ø¬Ø§Ùƒ']",
            "['Ø§Ù„Ù…ÙŽØ´ÙÙŠÙ…ÙŽØ©', 'Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø§Ù„Ø­Ø¨Ù„ Ø§Ù„Ø³Ø±ÙŠ']",
            "['Ù…Ø¯ÙŠÙ†Ø© Ø¬Ø¨ÙŠÙ„ Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ©', 'Ù…Ø¯ÙŠÙ†Ø© Ø¬Ø¨ÙŠÙ„ Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ©', 'Ù…Ø¯ÙŠÙ†Ø© Ø¬Ø¨ÙŠÙ„ Ø§Ù„Ù„Ø¨Ù†Ø§Ù†ÙŠØ©']",
            "['ØªØ¨Ù„ÙŠØ³ÙŠ', 'ØªØ¨Ù„ÙŠØ³ÙŠ']"
        ]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shots_question[i] + "\n\n" + self.a_head + "<answer>" + shots_answer[i] + "</answer>\n\n"

        for q, a in zip(question, answer):
            text = self.prompt_template.format(examples, q, a["text"] if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_sqs(self, data):
        question1 = data["question1"]
        question2 = data["question2"]
        questions = zip(question1, question2)
        labels = data["label"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(question1), self.shots, replace=False)
        #     for i in indices:
        #         # examples += self.q_head + question1[i] + "\n" + question2[i] + "\n\n" + self.a_head + "<answer>" + labels[i] + "</answer>\n\n"
        #         examples += self.q_head
        #         examples += "Ø³Ø¤Ø§Ù„ Ù¡: " if self.lang == "ar" else "Question 1: "
        #         examples += question1[i] + "\n"
        #         examples += "Ø³Ø¤Ø§Ù„ Ù¢: " if self.lang == "ar" else "Question 2: "
        #         examples += question2[i] + "\n\n"
        #         examples += self.a_head + "<answer>" + str(labels[i]) + "</answer>\n\n"

        shots_question1 = [
            "Ù…Ù† Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¹Ù…Ù„ ØŸ",
            "Ù…Ù† Ù…Ø§Ø°Ø§ ØªØªÙƒÙˆÙ† Ø­Ø¬Ø±Ø§Øª Ø§Ù„Ù‚Ù„Ø¨ Ù„Ø¯Ù‰ Ø§Ù„Ø¶ÙØ¯Ø¹ØŸ",
            "Ù…Ø§ Ù‡ÙŠ Ø£Ù‡Ù…ÙŠØ© Ù…ÙˆÙ‚Ø¹ Ø¬ÙˆØ¬Ù„ØŸ",
            "ÙÙŠ Ø£ÙŠ Ø¹Ø§Ù… ÙƒØ§Ù†Øª ØºØ²ÙˆØ© Ø¨Ù†ÙŠ Ø§Ù„Ù†Ø¶ÙŠØ±ØŸ",
            "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø´Ø¹Ø¨ÙŠ Ù„Ù„Ø«Ø¢Ù„ÙŠÙ„ØŸ",
        ]
        shots_question2 = [
            "Ù…Ø§ Ù‡Ùˆ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¹Ù…Ù„ ØŸ",
            "ÙƒÙŠÙ ØªÙƒÙˆÙ† Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø¯Ù…ÙˆÙŠØ© ÙÙŠ Ù‚Ù„Ø¨ Ø§Ù„Ø¶ÙØ¯Ø¹ØŸ",
            "Ù…Ø§ Ù‡Ùˆ Ù…ÙˆÙ‚Ø¹ Ø¬ÙˆØ¬Ù„ØŸ",
            "Ù…ØªÙ‰ ØºØ²Ø§ Ø§Ù„Ù†Ø¨ÙŠ Ø¨Ù†ÙŠ Ø§Ù„Ù†Ø¶ÙŠØ±ØŸ",
            "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø§Ù„Ø·Ø¨ÙŠ Ù„Ù„Ø«Ø§Ù„ÙˆÙ„ØŸ"
        ]
        shots_labels = ["1", "0", "0", "1", "0"]
        examples = ""
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head
                examples += "Ø³Ø¤Ø§Ù„ Ù¡: " if self.lang == "ar" else "Question 1: "
                examples += shots_question1[i] + "\n"
                examples += "Ø³Ø¤Ø§Ù„ Ù¢: " if self.lang == "ar" else "Question 2: "
                examples += shots_question2[i] + "\n\n"
                examples += self.a_head + "<answer>" + str(shots_labels[i]) + "</answer>\n\n"

        for (question1, question2), label in zip(questions, labels):
            q_res = "Ø³Ø¤Ø§Ù„ Ù¡: "+ question1 + "\n" + "Ø³Ø¤Ø§Ù„ Ù¢: " + question2
            text = self.prompt_template.format(examples, q_res, label if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_claim(self, data):
        claims = data["claim_s"]
        flags = data["fake_flag"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(claims), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + claims[i] + "\n\n" + self.a_head + "<answer>" + str(flags[i]) + "</answer"">\n\n"

        examples = ""
        shots_claims = [
            "Ø§Ù„Ø­Ø±Ø¨ Ø¬Ù†ÙˆØ¨ÙŠ Ø§Ù„Ø³ÙˆØ¯Ø§Ù† ØªÙ‡ÙˆÙŠ Ø¨Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¬Ù†ÙŠÙ‡",
            "Ø§Ø±ØªÙØ§Ø¹ ÙÙŠ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ Ø¹Ø§Ù„Ù…ÙŠØ§Ù‹ Ù…Ø¹ Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø¯ÙˆÙ„Ø§Ø±",
            "Ø¨Ø±Ù„ÙŠÙ†: Ù„Ø§ Ø­Ø±Ø¨ ØªØ¬Ø§Ø±ÙŠØ© Ø¨ÙŠÙ† Ø£Ù…ÙŠØ±ÙƒØ§ ÙˆØ£ÙˆØ±ÙˆØ¨Ø§",
            "Ø§Ù„Ø¬ÙŠØ´ Ø§Ù„Ø³ÙˆØ±ÙŠ ÙŠØ³Ù…Ø­ Ù„Ù„Ù…Ø¯Ù†ÙŠÙŠÙ† ÙÙŠ Ø§Ù„ØºÙˆØ·Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ© Ø¨Ø§Ù„Ø¨Ù‚Ø§Ø¡",
            "Ø±ÙˆØ³ÙŠØ§ Ù…Ø³ØªØ¹Ø¯Ø© Ù„Ø£ÙŠ Ø­Ø±Ø¨ ØªØ¬Ø§Ø±ÙŠØ© Ø¶Ø¯ ÙˆØ§Ø´Ù†Ø·Ù†"
        ]
        shots_flags = ["1", "0", "0", "1", "1"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shots_claims[i] + "\n\n" + self.a_head + "<answer>" + str(shots_flags[i]) + "</answer>\n\n"

        for c, f in zip(claims, flags):
            text = self.prompt_template.format(examples, c, f if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_stance(self, data):
        sent1 = data["s1"]
        sent2 = data["s2"]
        questions = zip(sent1, sent2)
        stances = data["stance"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(sent1), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head
        #         examples += "Ø¬Ù…Ù„Ø© Ù¡: " if self.lang == "ar" else "Sentence 1: "
        #         examples += sent1[i] + "\n"
        #         examples += "Ø¬Ù…Ù„Ø© Ù¢: " if self.lang == "ar" else "Sentence 2: "
        #         examples += sent2[i] + "\n\n"
        #         examples += self.a_head + "<answer>" + str(stances[i]) + "</answer>\n\n"

        examples = ""
        shots_sent1 = [
            "Ø§Ù„Ø¹Ø§Ù„Ù… ÙŠØªØ±Ù‚Ø¨ Ù…ÙˆÙ‚Ù Ø¥ÙŠØ±Ø§Ù†ÙŠ Ø­ÙˆÙ„ Ù‡Ø¨ÙˆØ· Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù†ÙØ·",
            "ÙÙ†Ø§Ù†Ø© Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ© ØªÙÙˆØ² Ø¨Ø¬Ø§Ø¦Ø²Ø© Ø¢Ø¨Ù„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„ØªØµÙˆÙŠØ± 2020",
            "Ø§Ù„Ø¥ÙŠØ²ÙŠØ¯ÙŠÙˆÙ† ÙŠØ­ØªÙÙ„ÙˆÙ† Ø¨Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ Ø§Ù„Ø£Ø­Ù…Ø± Ø¹Ù„Ù‰ Ø·Ø±ÙŠÙ‚ØªÙ‡Ù…",
            "ØªÙˆÙ‚ÙŠØ¹ Ù…Ø°ÙƒØ±Ø© ØªÙØ§Ù‡Ù… Ø¥Ù…Ø§Ø±Ø§ØªÙŠØ© ÙƒÙˆØ±ÙŠØ© ÙÙŠ Ù…Ø¬Ø§Ù„ Ø§Ù„Ø·Ø§Ù‚Ø©",
            "Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠØ© Ø¶Ø­ÙŠØ© Ø§Ù„Ø­Ø±Ø¨ Ø¨ÙŠÙ† ÙˆØ§Ø´Ù†Ø·Ù† ÙˆØ¨ÙƒÙŠÙ†"
        ]
        shots_sent2 = [
            "ØªØ±Ø§Ø¬Ø¹ Ù…ÙØ§Ø¬Ø¦ Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ù†ÙØ·.. ÙˆØªØ±Ù‚Ø¨ Ø¹Ø§Ù„Ù…ÙŠ Ù„Ù€ÙƒÙ„Ù…Ø© ØªØ±Ø§Ù…Ø¨",
            "Ø¬Ø§Ø¦Ø²Ø© Ø³ÙˆÙ†ÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© Ù„Ù„ØªØµÙˆÙŠØ± 2018 Ù…Ù† Ù†ØµÙŠØ¨ ÙÙ†Ø§Ù†Ø© Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ©",
            "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡ Ø§Ù„Ø£Ø­Ù…Ø± Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙÙ„ Ø¨Ù‡ Ø§Ù„Ø¥ÙŠØ²ÙŠØ¯ÙŠÙˆÙ† ØŸ",
            "Ù…ØµØ¯Ø± ÙˆØ§Ù„ÙˆÙƒØ§Ù„Ø© Ø§Ù„ÙƒÙˆØ±ÙŠØ© Ù„Ù„Ø·Ø§Ù‚Ø© ØªÙˆÙ‚Ø¹Ø§Ù† Ù…Ø°ÙƒØ±Ø© ØªÙØ§Ù‡Ù…",
            "Ø§Ù„Ø­Ø±Ø¨ Ø§Ù„ØµÙŠÙ†ÙŠØ© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© ØªØ·ÙŠØ­ Ø§Ù„Ø£Ø³Ù‡Ù… Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠØ©",
        ]
        shots_stances = ["0", "0", "1", "1", "1"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head
                examples += "Ø¬Ù…Ù„Ø© Ù¡: " if self.lang == "ar" else "Sentence 1: "
                examples += shots_sent1[i] + "\n"
                examples += "Ø¬Ù…Ù„Ø© Ù¢: " if self.lang == "ar" else "Sentence 2: "
                examples += shots_sent2[i] + "\n\n"
                examples += self.a_head + "<answer>" + str(shots_stances[i]) + "</answer>\n\n"
 
        for (sent1, sent2), stance in zip(questions, stances):
            q_res = ""
            if "en" in self.lang:
                q_res = "Sentence 1: "+ sent1 + "\n" + "Sentence 2: " + sent2
            else:
                q_res = "Ø¬Ù…Ù„Ø© Ù¡: "+ sent1 + "\n" + "Ø¬Ù…Ù„Ø© Ù¢: " + sent2
            text = self.prompt_template.format(examples, q_res, stance if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_wsd(self, data):
        exs = data["ex"]
        words = data["word"]
        defs = data["def"]
        labels = data["label"]
        qs = zip(exs, words, defs)
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(exs), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head
        #         examples += "Ø¬Ù…Ù„Ø©: " if self.lang == "ar" else "Sentence: "
        #         examples += exs[i] + "\n"
        #         examples += "ÙƒÙ„Ù…Ø©: " if self.lang == "ar" else "Word: "
        #         examples += words[i] + "\n"
        #         examples += ":ØªØ¹Ø±ÙŠÙ" if self.lang == "ar" else "Definition: "
        #         examples += defs[i] + "\n\n"
        #         examples += self.a_head + "<answer>" + str(labels[i]) + "</answer>\n\n"

        examples = ""
        shot_words = [
            "Ø§Ù†Ø¯Ø³",
            "Ù‡ÙˆØ³",
            "Ø¹ØªÙ„",
            "Ø®Ø¨Ø¨",
            "ÙˆØ§Ø·Ù†"
        ]
        shot_defs = [
            ": Ø§Ù†Ø¯Ø³ Ø¨ÙŠÙ† Ø§Ù„Ù†Ø§Ø³: Ø§Ø®ØªÙÙ‰ØŒ ØªØ³Ù„Ù„ Ø®ÙÙŠØ© Ø¨ÙŠÙ†Ù‡Ù…",
            ": Ù‡ÙˆØ³ Ø§Ù„Ø³Ø±Ù‚Ø©: (Ø·Ø¨) Ù†Ø²Ø¹Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø±Ù‚Ø© ÙÙŠ ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„Ø§Øª",
            ": Ø¹ØªÙ„Ù‡ Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù† Ø¬Ø°Ø¨Ù‡ ÙˆØ¬Ø±Ù‡ Ø¨Ø¹Ù†Ù :- { } .",
            ": Ù†ÙˆØ¹ Ù…Ù† Ø£Ù†ÙˆØ§Ø¹ Ø³ÙŠØ± Ø§Ù„ÙØ±Ø³ Ø¨Ø­ÙŠØ« ØªÙ…Ø³ Ø£Ù‚Ø¯Ø§Ù…Ù‡Ø§ Ø§Ù„Ø£Ø±Ø¶ Ø¨Ø´ÙƒÙ„ Ù…ØªØªØ§Ø¨Ø¹",
            ": ÙˆØ§ÙÙ‚Ù‡ Ø¹Ù„ÙŠÙ‡"
        ]
        shot_exs = [
            ":-Ø§Ù†Ø¯Ø³ ÙÙŠ Ø§Ù„ÙØ±Ø§Ø´ Ø®Ø´ÙŠØ© Ø§Ù„Ø¨Ø±Ø¯.",
            ":-ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ù‡ÙˆØ³ Ø§Ù„Ø³Ø±Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø£Ù†Ù‡Ø§ ØºÙ†ÙŠØ©.",
            "Ø¹ØªÙ„ Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ Ø²Ù†ÙŠÙ…",
            ":-Ù…Ø´Ù‰ Ø®Ø¨Ø¨Ø§.",
            ":-ÙˆØ§Ø·Ù†Ù‡ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø§ÙˆÙ† Ù…Ø¹Ù‡ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³ÙˆØ±."
        ]
        shot_labels = ["0", "1", "0", "1", "0"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head
                examples += "Ø¬Ù…Ù„Ø©: " if self.lang == "ar" else "Sentence: "
                examples += shot_exs[i] + "\n"
                examples += "ÙƒÙ„Ù…Ø©: " if self.lang == "ar" else "Word: "
                examples += shot_words[i] + "\n"
                examples += ":ØªØ¹Ø±ÙŠÙ" if self.lang == "ar" else "Definition: "
                examples += shot_defs[i] + "\n\n"
                examples += self.a_head + "<answer>" + str(shot_labels[i]) + "</answer>\n\n"

        for (eg, word, de), label in zip(qs, labels):
            q_res = ""
            if self.lang == "en":
                q_res = "Sentence: "+ eg + "\n" + "Word: " + word + "\n" + "Definition: " + de
            else:
                q_res = "Ø¬Ù…Ù„Ø©: "+ eg + "\n" + "ÙƒÙ„Ù…Ø©: " + word + "\n" + ":ØªØ¹Ø±ÙŠÙ" + de
            text = self.prompt_template.format(examples, q_res, label if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def format_prompt_dialect(self, data):
        tweets = data["tweet"]
        dialect = data["dialect"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(tweets), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + tweets[i] + "\n\n" + self.a_head + "<answer>" + str(dialect[i]) + "</answer>\n\n"

        examples = ""
        shot_tweets = [
            "Ø§ÙˆÙ„ Ù…Ø±Ø© Ù…Ù† Ø¹Ø±ÙØª Ù…Ø¹Ø±Ø¶ Ø§Ù„ÙƒØªØ§Ø¨ Ø²Ø­Ù…Ø© ÙˆÙ…Ù† Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø¹Ø±Ø¶ ÙƒÙ„Ù‡Ø§ #Ù…Ø¹Ø±Ø¶_Ø§Ù„ÙƒÙˆÙŠØª_Ø§Ù„Ø¯ÙˆÙ„ÙŠ_Ù„Ù„ÙƒØªØ§Ø¨",
            "@140041Saud Ø§Ù„Ø±ÙŠØ§Ø¶ Ø­ÙŠ Ø§Ù„ÙˆØ§Ø­Ø©ØªÙ‚Ø§Ø·Ø¹ Ø´Ø§Ø±Ø¹ Ø±ÙØ­Ø§Ø¡ Ù…Ø¹ Ø·Ø±ÙŠÙ‚ Ø§Ø¨ÙˆØ¨ÙƒØ± Ø§Ù„ØµØ¯ÙŠÙ‚.Ù…ÙˆÙ‚Ø¹Ù†Ø§ Ø¹Ø¨Ø± Ø®Ø±Ø§Ø¦Ø· Ø¬ÙˆØ¬Ù„:https://t.co/7nNz2nyzuB",
            "Ø§Ù„Ø£Ø±Ø¬Ù†ØªÙŠÙ† ÙÙŠ Ø£Ø±Ø¶Ù‡Ø§ Ùˆ Ø¨ÙŠÙ† Ø¬Ù…Ù‡ÙˆØ±Ù‡Ø§ Ø®Ø³Ø±Ø§Ù†Ù‡ Ù…Ù† Ø§Ù„Ø¨Ø§Ø±ØºÙˆØ§ÙŠ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†ØŒ ÙŠÙ‚ÙˆÙ„ÙˆÙ† Ø§Ù„Ø£Ø±Ø¬Ù†ØªÙŠÙ† Ù…Ù†ØªØ®Ø¨ ÙÙŠ Ù„Ø§Ø¹Ø¨ÙŠÙ† ÙƒØ¨Ø§Ø± Ø­ØªÙ‰ Ø¨Ø¯ÙˆÙ† Ù…ÙŠØ³ÙŠ Ø±Ø§Ø­ ÙŠÙˆØµÙ„ÙˆÙ† Ø§Ù„Ø«Ù„Ø§Ø« Ù†Ù‡Ø§Ø¦ÙŠØ§Øª",
            "ÙˆØµÙ„Øª ØµØ§Ù„Ø© 5 ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ù…ØªØ£Ø®Ø±Ø©. Ø£Ø®Ø°Øª #Ø£ÙˆØ¨Ø± Ø´Ø§Ø¨ Ù…ÙˆØ§Ø·Ù†ØŒ Ù„Ø·Ù ÙˆÙ…Ù‡Ù†ÙŠØ©ØŒ Ø³ÙŠØ§Ø±ØªÙ‡ Ù†Ø¸ÙŠÙØ©ØŒ ÙˆÙ‚Ø¯Ù… Ù‚Ø§Ø±ÙˆØ±Ø© Ù…Ø§Ø¡.Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù‡ Ù„Ø£Ù‡Ù„Ù‡ØŒ ÙˆÙŠØ¨Ø§Ø±Ùƒ Ù„Ù‡ ÙÙŠ Ø±Ø²Ù‚Ù‡.",
            "RT @Q8Pay: @Q8Pay ÙˆÙ‡Ø°ÙˆÙ„Ø§ Ù†ÙØ³Ù‡Ù… ÙˆØ£Ø±Ø®Øµ ÙˆØ´Ø­Ù† Ø­ÙƒÙˆÙ…ÙŠ Ù…Ø¨Ø§Ø´Ø± Ø±Ø®ÙŠØµ Ù…Ù† #Ø§Ù…Ø§Ø²ÙˆÙ† Ø§Ù„Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠÙˆØ§Ø°ÙƒØ± Ø§Ø°Ø§ Ø§Ø´ØªØ±ÙŠØª Ø¨Ø£ÙƒØ«Ø± Ù…Ù† 60Â£ ÙŠØ·Ù„Ø¹ Ø§Ù„Ø´Ø­Ù† Ù…Ø¬Ø§Ù†ÙŠhttps://t.câ€¦"
        ]
        shot_dialects = ["0", "1", "0", "1", "0"]

        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shot_tweets[i] + "\n\n" + self.a_head + "<answer>" + shot_dialects[i] + "</answer>\n\n"
 
        for t, d in zip(tweets, dialect):
            text = self.prompt_template.format(examples, t, d if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}
    

    def format_prompt_sarcasm(self, data):
        tweets = data["tweet"]
        sarcasm = data["sarcasm"]
        texts = []

        # examples = ""
        # if self.shots > 0:
        #     examples = self.e_head
        #     indices = np.random.choice(len(tweets), self.shots, replace=False)
        #     for i in indices:
        #         examples += self.q_head + tweets[i] + "\n\n" + self.a_head + "<answer>" + str(sarcasm[i]) + "</answer>\n\n"

        examples = ""
        shot_tweets = [
            "Ø­ØªÙŠ Ø¬ÙˆØ¬Ù„ Ù…Ø´ Ù…ØµØ¯Ù‚ Ø§Ù†ÙŠ ÙÙŠ Ø¨ÙŠØª Ø¯Ù…ÙŠØ§Ø· ðŸ’” https://t.co/GBTmGmMRiG",
            "Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ Ù‡Ø±Ø¨Ù†Ø§ Ù…Ù†Ù‡Ø§ Ø£ÙŠØ§Ù… Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¹Ø³ÙƒØ±ÙŠ Ù„Ø§ Ø²Ø§Ù„Øª ØªØ·Ø§Ø±Ø¯Ù†Ø§ ÙˆØ³ØªØ¸Ù„ Ø¥Ù„Ù‰ Ø£Ù† Ù†ÙˆØ§Ø¬Ù‡Ù‡Ø§ ÙˆÙ†Ø¬ÙŠØ¨ Ø¹Ù„ÙŠÙ‡Ø§",
            "ØªØ§ÙŠÙ…Ù„Ø§ÙŠÙ† ÙŠÙ„ÙŠÙ‚ Ø¨ÙŠÙ‡ ÙÙŠÙ„Ù… 'Ø§Ù„Ø£Ø±Ù‡Ø§Ø¨ ÙˆØ§Ù„ÙƒØ¨Ø§Ø¨' Ø¨Ø¯Ø®Ù„Ø© ÙŠØ³Ø±Ø§ Ø§Ù„Ù…ÙØ§Ø¬Ø£Ø© ðŸ˜ŒðŸ˜ƒ",
            "@Ahmed_ALHasani ÙˆÙŠÙ†Ø¯ÙˆØ² 10 Ù…Ù…ØªØ§Ø² Ø¨Ø³ Ø¬Ù„Ø¨ Ù…Ø´Ø§ÙƒÙ„ ÙˆØ§Ø¬Ø¯ ÙÙŠ Ù„Ø§Ø¨ ØªÙˆØ¨ Ù…Ù†Ù‡Ø§ Ø§Ù„Ø§Ø¶Ø§Ø© Ø§Ù„ÙŠ Ø­Ù„ØªÙ‡Ø§ ÙˆÙ…Ù†Ù‡Ø§ Ø§Ù†Ù‡ Ø§Ù„Ø¬Ù‡Ø§Ø² ÙŠØ¹Ù„Ù‚ Ø¹Ù„Ù‰ ÙØªØ±Ø§Øª Ø§Ø°Ø§ ØªØ±ÙƒØªÙ‡ Ù…Ù† Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù…",
            "Ù„Ù…Ø§ Ø§Ø´ÙˆÙ Ù‡ÙŠÙ„Ø§Ø±ÙŠ ÙƒÙ„Ù†ØªÙˆÙ† ÙˆØ¯ÙˆÙ†Ø§Ù„Ø¯ ØªØ±Ù…Ø¨ ÙŠØªÙ‡Ø§ÙˆØ´ÙˆÙ† Ø§ØªØ°ÙƒØ± ÙØ§Ù… the campaign"
        ]
        shot_sarcasm = ["1", "0", "1", "0", "1"]
        if self.shots > 0:
            examples = self.e_head
            for i in range(self.shots):
                examples += self.q_head + shot_tweets[i] + "\n\n" + self.a_head + "<answer>" + shot_sarcasm[i] + "</answer>\n\n"

        for t, s in zip(tweets, sarcasm):
            text = self.prompt_template.format(examples, t, s if not self.test_mode else "") + self.EOS_TOKEN
            texts.append(text)
        
        return {"text": texts}

    def construct_prompt(self, task, lang):
        if lang == "en":
            self.prompt_template = "Below is an instruction that describes a task, paired with an input that provides further context.\n"
            self.prompt_template += "Write a response that appropriately completes the request.\n"
            self.prompt_template += "Dont say anything except the answer. Give the final answer between answer tags: <answer>...</answer>.\n"
            self.prompt_template += "\n"
            self.prompt_template += "### Instruction:\n"
            self.prompt_template += f"{self.task_instructions[task]}\n"
            self.prompt_template += "\n"
            self.prompt_template += "{}"
            self.prompt_template += "\n"
            self.prompt_template += "-------------------\n" if self.shots>0 else ""
            self.prompt_template += f"### Question:\n"
            self.prompt_template += "{}"
            self.prompt_template += "\n\n"
            self.prompt_template += f"### Response:\n"
            self.prompt_template += "{}"

        elif lang == "ar":
            self.prompt_template = "ÙŠÙˆØ¬Ø¯ Ø£Ø¯Ù†Ø§Ù‡ ØªØ¹Ù„ÙŠÙ…Ø§Øª ØªØµÙ Ù…Ù‡Ù…Ø©ØŒ Ù…Ù‚ØªØ±Ù†Ø© Ø¨Ø¥Ø¯Ø®Ø§Ù„ ÙŠÙˆÙØ± Ø³ÙŠØ§Ù‚Ù‹Ø§ Ø¥Ø¶Ø§ÙÙŠÙ‹Ø§." + "\n"
            self.prompt_template += "Ø§ÙƒØªØ¨ Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙŠ ÙŠÙƒÙ…Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø§Ø³Ø¨." + "\n"
            self.prompt_template += "Ù„Ø§ ØªÙ‚Ù„ Ø£ÙŠ Ø´ÙŠØ¡ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©. Ø£Ø¹Ø· Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¨ÙŠÙ† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©: <answer>...</answer>.\n"
            self.prompt_template += "\n"
            self.prompt_template += ":ØªØ¹Ù„ÙŠÙ…Ø§Øª" + "###" + "\n"
            self.prompt_template += f"{self.task_instructions_ar[task]}\n"
            self.prompt_template += "\n"
            self.prompt_template += "{}"
            self.prompt_template += "\n"
            self.prompt_template += "-------------------\n" if self.shots>0 else ""
            self.prompt_template += ":Ø³Ø¤Ø§Ù„" + "###" + "\n"
            self.prompt_template += "{}"
            self.prompt_template += "\n\n"
            self.prompt_template += ":Ø¥Ø¬Ø§Ø¨Ø©" + "###" + "\n"
            self.prompt_template += "{}"

        else:
            if self.logger is not None:
                self.logger(lang + " not supported")
            exit()

        if self.logger is not None:
            self.logger("PROMPT:")
            self.logger(self.prompt_template)
            self.logger("\n\n")

    def get_dataset(self, task, lang="ar"):
        self.lang = lang
        print(self.lang, "==========================")

        self.q_head =  "## Question:\n" if self.lang == "en" else (":Ø³Ø¤Ø§Ù„" + "##" + "\n")
        self.a_head = "## Response:\n" if self.lang == "en" else (":Ø¥Ø¬Ø§Ø¨Ø©" + "##" + "\n")
        self.e_head = "EXAMPLES:\n" if self.lang == "en" else "Ø£Ù…Ø«Ù„Ø©:\n"
        
        self.construct_prompt(task, lang)
        task_split = task + "_" + self.split

        if os.path.exists(self.dataset_names[task_split]) and self.dataset_names[task_split].endswith(".csv"):
            dataset = load_dataset("csv", data_files=self.dataset_names[task_split])["train"]

        elif os.path.exists(self.dataset_names[task_split]) and self.dataset_names[task_split].endswith(".tsv"):
            df = pd.read_csv(self.dataset_names[task_split], delimeter="\t")
            dataset = Dataset.from_pandas(df)["train"]

        elif os.path.exists(self.dataset_names[task_split]) and self.dataset_names[task_split].endswith(".pkl"):
            with open(self.dataset_names[task_split], 'rb') as pickle_file:
                arabic_docs=pickle.load(pickle_file)

            flat_data = []
            for url, sections in arabic_docs.items():
                for section_name, section_data in sections.items():
                    flat_data.append({
                        'input_text': section_data['document'],
                        'target_text': section_data['summary'],
                    })

            df = pd.DataFrame(flat_data)
            dataset = Dataset.from_pandas(df)

        else:
            dataset_name = self.dataset_names[task_split]
            subset_name = self.subset_names[task_split]
            dataset = load_dataset(dataset_name, subset_name, split=self.dataset_splits[task_split], trust_remote_code=True)

            # save as csv
            # df = pd.DataFrame(dataset)
            # df.to_csv("./train.csv", index=False)

        self.size = dataset.num_rows
        dataset = dataset.map(self.prompt_func_map[task_split], batched = True)
        
        if self.split == "train" and self.shuffle:
            dataset = dataset.shuffle(seed=42)

        if self.logger is not None:
            self.logger("\n\n")
            self.logger("DATASET SUMMARY:")
            self.logger(str(dataset))
            self.logger("\n\n")

            self.logger("EXAMPLE DATA INSTANCE:")
            self.logger(dataset["text"][-1])
            self.logger("\n\n")
        else:
            print("\n\n")
            print(task)
            print("DATASET SUMMARY")
            print(str(dataset))
            print("\n\n")

            print("EXAMPLE DATA INSTANCE:")
            print(dataset["text"][0])
            print()
            print("\n\n") 
            
            print("Length:", len(dataset["text"]))
            print("\n")

        return dataset


if __name__ == "__main__":
    # FT_Dataset("", split="test", shots=5).get_dataset("sentiment", "ar")
    # FT_Dataset("", split="train", shots=5).get_dataset("pos_tagging", "ar")
    FT_Dataset("", split="test", shots=5).get_dataset("summarization", "en")
    # FT_Dataset("", split="test", shots=5).get_dataset("translation", "ar")
    # FT_Dataset("", split="train", shots=5).get_dataset("paraphrasing", "en")
    # FT_Dataset("", split="test", shots=3).get_dataset("transliteration", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("sqs", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("stance", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("claim", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("wsd", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("GQA", "en")
    # FT_Dataset("", split="test", shots=5).get_dataset("sarcasm", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("dialect", "ar")
    # FT_Dataset("", split="test", shots=5).get_dataset("hate", "ar")
    # FT_Dataset("", split="test", shots=3).get_dataset("offensive", "en")

